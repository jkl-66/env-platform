#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®AIå›¾åƒç”Ÿæˆé…ç½®æŒ‡å—

æœ¬è„šæœ¬å±•ç¤ºå¦‚ä½•é…ç½®çœŸæ­£çš„AIå›¾åƒç”Ÿæˆæ¨¡å‹æ¥æ›¿ä»£ç¤ºä¾‹å›¾åƒ
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def show_setup_guide():
    """æ˜¾ç¤ºçœŸå®AIå›¾åƒç”Ÿæˆçš„é…ç½®æŒ‡å—"""
    print("ğŸ¨ çœŸå®AIå›¾åƒç”Ÿæˆé…ç½®æŒ‡å—")
    print("=" * 60)
    
    print("\nğŸ“‹ å½“å‰çŠ¶æ€:")
    print("â€¢ ç³»ç»Ÿç›®å‰ä½¿ç”¨ç¤ºä¾‹å›¾åƒæ•°æ®æ¥æ¨¡æ‹ŸAIå›¾åƒç”Ÿæˆ")
    print("â€¢ è¦è·å¾—çœŸæ­£çš„AIç”Ÿæˆå›¾åƒä½œå“ï¼Œéœ€è¦é…ç½®ä»¥ä¸‹æ¨¡å‹ä¹‹ä¸€:")
    
    print("\nğŸ”§ é…ç½®é€‰é¡¹:")
    
    print("\n1ï¸âƒ£ ä½¿ç”¨Stable Diffusion (æ¨è)")
    print("   â€¢ å®‰è£…: pip install diffusers transformers accelerate")
    print("   â€¢ éœ€è¦: 4GB+ GPUæ˜¾å­˜")
    print("   â€¢ ä¼˜ç‚¹: é«˜è´¨é‡å›¾åƒï¼Œå¼€æºå…è´¹")
    print("   â€¢ ç¤ºä¾‹ä»£ç :")
    print("     ```python")
    print("     from diffusers import StableDiffusionPipeline")
    print("     pipe = StableDiffusionPipeline.from_pretrained(")
    print("         'runwayml/stable-diffusion-v1-5'")
    print("     )")
    print("     ```")
    
    print("\n2ï¸âƒ£ ä½¿ç”¨DALL-E API")
    print("   â€¢ å®‰è£…: pip install openai")
    print("   â€¢ éœ€è¦: OpenAI APIå¯†é’¥")
    print("   â€¢ ä¼˜ç‚¹: é«˜è´¨é‡ï¼Œæ— éœ€æœ¬åœ°GPU")
    print("   â€¢ ç¼ºç‚¹: éœ€è¦ä»˜è´¹API")
    
    print("\n3ï¸âƒ£ ä½¿ç”¨æœ¬åœ°GANæ¨¡å‹")
    print("   â€¢ éœ€è¦: è®­ç»ƒå¥½çš„GANæ¨¡å‹")
    print("   â€¢ ä¼˜ç‚¹: å®Œå…¨æœ¬åœ°åŒ–")
    print("   â€¢ ç¼ºç‚¹: éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®")
    
    print("\nğŸ› ï¸ ä¿®æ”¹æ­¥éª¤:")
    print("1. é€‰æ‹©ä¸Šè¿°é…ç½®é€‰é¡¹ä¹‹ä¸€")
    print("2. å®‰è£…ç›¸åº”çš„ä¾èµ–åŒ…")
    print("3. ä¿®æ”¹ ecology_image_generator.py ä¸­çš„ _generate_with_diffusion æ–¹æ³•")
    print("4. ç¡®ä¿ diffusion_pipeline æ­£ç¡®åˆå§‹åŒ–")
    
    print("\nğŸ“ ç›¸å…³æ–‡ä»¶:")
    print(f"â€¢ ä¸»è¦ç”Ÿæˆå™¨: {project_root}/src/models/ecology_image_generator.py")
    print(f"â€¢ äº¤äº’ç•Œé¢: {project_root}/scripts/interactive_ecology_image_demo.py")
    print(f"â€¢ é…ç½®ç¤ºä¾‹: {project_root}/docs/huggingface_setup_guide.md")
    
    print("\nâš ï¸ é‡è¦æç¤º:")
    print("â€¢ çœŸå®çš„AIå›¾åƒç”Ÿæˆéœ€è¦è¾ƒå¤§çš„è®¡ç®—èµ„æº")
    print("â€¢ å»ºè®®ä½¿ç”¨GPUåŠ é€Ÿä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½")
    print("â€¢ ç”Ÿæˆæ—¶é—´å¯èƒ½éœ€è¦å‡ ç§’åˆ°å‡ åˆ†é’Ÿä¸ç­‰")
    print("â€¢ ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å­˜å‚¨æ¨¡å‹æ–‡ä»¶")

def create_stable_diffusion_example():
    """åˆ›å»ºStable Diffusioné…ç½®ç¤ºä¾‹"""
    example_code = '''
# Stable Diffusion é…ç½®ç¤ºä¾‹
# åœ¨ ecology_image_generator.py çš„ _build_model æ–¹æ³•ä¸­æ·»åŠ :

try:
    from diffusers import StableDiffusionPipeline
    import torch
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # åŠ è½½Stable Diffusionæ¨¡å‹
    self.diffusion_pipeline = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        safety_checker=None,  # å¯é€‰ï¼šç¦ç”¨å®‰å…¨æ£€æŸ¥å™¨
        requires_safety_checker=False
    )
    
    self.diffusion_pipeline = self.diffusion_pipeline.to(device)
    
    # å¯ç”¨å†…å­˜ä¼˜åŒ–ï¼ˆå¦‚æœä½¿ç”¨GPUï¼‰
    if device == "cuda":
        self.diffusion_pipeline.enable_attention_slicing()
        self.diffusion_pipeline.enable_memory_efficient_attention()
    
    logger.info(f"Stable Diffusionæ¨¡å‹å·²åŠ è½½åˆ° {device}")
    
except ImportError:
    logger.warning("diffusersåº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨Stable Diffusion")
    self.diffusion_pipeline = None
except Exception as e:
    logger.warning(f"Stable DiffusionåŠ è½½å¤±è´¥: {e}")
    self.diffusion_pipeline = None
'''
    
    example_file = project_root / "examples" / "stable_diffusion_setup.py"
    example_file.parent.mkdir(exist_ok=True)
    
    with open(example_file, 'w', encoding='utf-8') as f:
        f.write(example_code)
    
    print(f"\nğŸ“„ Stable Diffusioné…ç½®ç¤ºä¾‹å·²ä¿å­˜åˆ°: {example_file}")

def check_current_setup():
    """æ£€æŸ¥å½“å‰çš„å›¾åƒç”Ÿæˆé…ç½®"""
    print("\nğŸ” æ£€æŸ¥å½“å‰é…ç½®...")
    
    try:
        # æ£€æŸ¥diffusers
        import diffusers
        print(f"âœ… diffusers å·²å®‰è£… (ç‰ˆæœ¬: {diffusers.__version__})")
    except ImportError:
        print("âŒ diffusers æœªå®‰è£…")
    
    try:
        # æ£€æŸ¥transformers
        import transformers
        print(f"âœ… transformers å·²å®‰è£… (ç‰ˆæœ¬: {transformers.__version__})")
    except ImportError:
        print("âŒ transformers æœªå®‰è£…")
    
    try:
        # æ£€æŸ¥torch
        import torch
        print(f"âœ… torch å·²å®‰è£… (ç‰ˆæœ¬: {torch.__version__})")
        print(f"   GPUå¯ç”¨: {'æ˜¯' if torch.cuda.is_available() else 'å¦'}")
        if torch.cuda.is_available():
            print(f"   GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
            print(f"   GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    except ImportError:
        print("âŒ torch æœªå®‰è£…")
    
    try:
        # æ£€æŸ¥PIL
        from PIL import Image
        print("âœ… PIL å·²å®‰è£…")
    except ImportError:
        print("âŒ PIL æœªå®‰è£…")
    
    # æ£€æŸ¥ç”Ÿæˆå™¨é…ç½®
    try:
        from src.models.ecology_image_generator import EcologyImageGenerator
        generator = EcologyImageGenerator()
        
        if hasattr(generator, 'diffusion_pipeline') and generator.diffusion_pipeline is not None:
            print("âœ… æ‰©æ•£æ¨¡å‹å·²é…ç½®")
        else:
            print("âš ï¸ æ‰©æ•£æ¨¡å‹æœªé…ç½®ï¼Œå°†ä½¿ç”¨ç¤ºä¾‹å›¾åƒ")
            
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå™¨æ£€æŸ¥å¤±è´¥: {e}")

def install_dependencies():
    """å®‰è£…å¿…è¦çš„ä¾èµ–"""
    print("\nğŸ“¦ å®‰è£…AIå›¾åƒç”Ÿæˆä¾èµ–...")
    
    dependencies = [
        "diffusers>=0.21.0",
        "transformers>=4.25.0",
        "accelerate>=0.20.0",
        "safetensors>=0.3.0",
        "xformers; sys_platform != 'darwin'",  # ä¸åœ¨macOSä¸Šå®‰è£…xformers
    ]
    
    print("å°†å®‰è£…ä»¥ä¸‹åŒ…:")
    for dep in dependencies:
        print(f"  â€¢ {dep}")
    
    confirm = input("\næ˜¯å¦ç»§ç»­å®‰è£…? (y/N): ").strip().lower()
    if confirm == 'y':
        import subprocess
        import sys
        
        for dep in dependencies:
            try:
                print(f"\nå®‰è£… {dep}...")
                subprocess.check_call([sys.executable, "-m", "pip", "install", dep])
                print(f"âœ… {dep} å®‰è£…æˆåŠŸ")
            except subprocess.CalledProcessError as e:
                print(f"âŒ {dep} å®‰è£…å¤±è´¥: {e}")
    else:
        print("å®‰è£…å·²å–æ¶ˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ AIå›¾åƒç”Ÿæˆé…ç½®å·¥å…·")
    print("=" * 40)
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. ğŸ“‹ æŸ¥çœ‹é…ç½®æŒ‡å—")
        print("2. ğŸ” æ£€æŸ¥å½“å‰é…ç½®")
        print("3. ğŸ“¦ å®‰è£…ä¾èµ–åŒ…")
        print("4. ğŸ“„ åˆ›å»ºé…ç½®ç¤ºä¾‹")
        print("5. ğŸšª é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹© (1-5): ").strip()
        
        if choice == '1':
            show_setup_guide()
        elif choice == '2':
            check_current_setup()
        elif choice == '3':
            install_dependencies()
        elif choice == '4':
            create_stable_diffusion_example()
        elif choice == '5':
            print("\nğŸ‘‹ å†è§ï¼")
            break
        else:
            print("\nâŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    main()