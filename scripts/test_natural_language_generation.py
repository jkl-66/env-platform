#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªç„¶è¯­è¨€å›¾åƒç”ŸæˆåŠŸèƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•æ–°å¢çš„è‡ªç„¶è¯­è¨€è¾“å…¥ç”Ÿæˆç¯å¢ƒè­¦ç¤ºå›¾åƒåŠŸèƒ½
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.models.ecology_image_generator import EcologyImageGenerator
import json
from datetime import datetime

def test_natural_language_generation():
    """æµ‹è¯•è‡ªç„¶è¯­è¨€å›¾åƒç”ŸæˆåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•è‡ªç„¶è¯­è¨€å›¾åƒç”ŸæˆåŠŸèƒ½")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = EcologyImageGenerator()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "description": "çƒŸé›¾ç¬¼ç½©çš„åŸå¸‚ï¼Œç©ºæ°”ä¸­å……æ»¡æœ‰æ¯’æ°”ä½“",
            "expected_themes": ["air_pollution"],
            "expected_warning_level": 4
        },
        {
            "description": "å¹²æ¶¸çš„æ²³åºŠï¼Œé±¼ç±»æ­»äº¡ï¼Œæ°´æºæ¯ç«­",
            "expected_themes": ["water_pollution"],
            "expected_warning_level": 4
        },
        {
            "description": "å¤±å»æ –æ¯åœ°çš„åŒ—æç†Šï¼Œå†°å·å¿«é€ŸèåŒ–",
            "expected_themes": ["climate_change", "wildlife_threat"],
            "expected_warning_level": 5
        },
        {
            "description": "å¤§è§„æ¨¡æ£®æ—ç ä¼ï¼ŒåŠ¨ç‰©æ— å®¶å¯å½’",
            "expected_themes": ["deforestation", "wildlife_threat"],
            "expected_warning_level": 4
        },
        {
            "description": "è½»å¾®çš„ç©ºæ°”æ±¡æŸ“ï¼Œéœ€è¦æ”¹å–„",
            "expected_themes": ["air_pollution"],
            "expected_warning_level": 2
        }
    ]
    
    results = []
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['description']}")
        
        try:
            # ç”Ÿæˆå›¾åƒ
            result = generator.generate_from_text(
                text_prompt=test_case['description'],
                style="realistic",
                num_images=1
            )
            
            # éªŒè¯ç»“æœ
            success = True
            issues = []
            
            # æ£€æŸ¥è­¦ç¤ºç­‰çº§
            if abs(result['warning_level'] - test_case['expected_warning_level']) > 1:
                success = False
                issues.append(f"è­¦ç¤ºç­‰çº§ä¸åŒ¹é…: æœŸæœ›{test_case['expected_warning_level']}, å®é™…{result['warning_level']}")
            
            # æ£€æŸ¥ä¸»é¢˜æ£€æµ‹
            detected_themes = result['text_analysis']['detected_themes']
            for expected_theme in test_case['expected_themes']:
                if expected_theme not in detected_themes:
                    success = False
                    issues.append(f"æœªæ£€æµ‹åˆ°æœŸæœ›ä¸»é¢˜: {expected_theme}")
            
            # æ£€æŸ¥ç”Ÿæˆçš„å›¾åƒ
            if not result['generated_images']:
                success = False
                issues.append("æœªç”Ÿæˆå›¾åƒ")
            
            # è®°å½•ç»“æœ
            test_result = {
                "test_case": i,
                "description": test_case['description'],
                "success": success,
                "issues": issues,
                "warning_level": result['warning_level'],
                "detected_themes": detected_themes,
                "enhanced_prompt": result['enhanced_prompt'],
                "environmental_impact": result['text_analysis']['environmental_impact']
            }
            
            results.append(test_result)
            
            if success:
                print(f"âœ… æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {', '.join(issues)}")
            
            print(f"   è­¦ç¤ºç­‰çº§: {result['warning_level']}/5")
            print(f"   æ£€æµ‹ä¸»é¢˜: {detected_themes}")
            print(f"   ç¯å¢ƒå½±å“: {result['text_analysis']['environmental_impact']}")
            print(f"   å¢å¼ºæç¤º: {result['enhanced_prompt'][:100]}...")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
            results.append({
                "test_case": i,
                "description": test_case['description'],
                "success": False,
                "issues": [f"å¼‚å¸¸: {str(e)}"],
                "error": str(e)
            })
    
    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    print("\nğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 30)
    
    passed = sum(1 for r in results if r['success'])
    total = len(results)
    
    print(f"æ€»æµ‹è¯•ç”¨ä¾‹: {total}")
    print(f"é€šè¿‡æµ‹è¯•: {passed}")
    print(f"å¤±è´¥æµ‹è¯•: {total - passed}")
    print(f"æˆåŠŸç‡: {passed/total*100:.1f}%")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path("outputs/natural_language_test")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    result_file = output_dir / f"test_results_{timestamp}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": timestamp,
            "summary": {
                "total_tests": total,
                "passed_tests": passed,
                "failed_tests": total - passed,
                "success_rate": passed/total*100
            },
            "test_results": results
        }, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ“ æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {result_file}")
    
    return passed == total

def test_prompt_enhancement():
    """æµ‹è¯•æç¤ºè¯å¢å¼ºåŠŸèƒ½"""
    print("\nğŸ”§ æµ‹è¯•æç¤ºè¯å¢å¼ºåŠŸèƒ½")
    print("=" * 30)
    
    generator = EcologyImageGenerator()
    
    test_prompts = [
        "çƒŸé›¾ç¬¼ç½©çš„åŸå¸‚",
        "å¹²æ¶¸çš„æ²³åºŠ",
        "å†°å·èåŒ–",
        "æ£®æ—ç ä¼",
        "æµ·æ´‹å¡‘æ–™æ±¡æŸ“"
    ]
    
    for prompt in test_prompts:
        enhanced = generator._enhance_warning_prompt(prompt, "realistic")
        print(f"åŸå§‹: {prompt}")
        print(f"å¢å¼º: {enhanced}")
        print("-" * 50)

def test_text_analysis():
    """æµ‹è¯•æ–‡æœ¬åˆ†æåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•æ–‡æœ¬åˆ†æåŠŸèƒ½")
    print("=" * 30)
    
    generator = EcologyImageGenerator()
    
    test_texts = [
        "ä¸¥é‡çš„ç©ºæ°”æ±¡æŸ“å¯¼è‡´é›¾éœ¾å¤©æ°”",
        "è½»å¾®çš„æ°´è´¨é—®é¢˜éœ€è¦å…³æ³¨",
        "å¤§è§„æ¨¡æ£®æ—ç ä¼å¨èƒç”Ÿç‰©å¤šæ ·æ€§",
        "æç«¯å¤©æ°”é¢‘å‘ï¼Œæ°”å€™å˜åŒ–åŠ å‰§"
    ]
    
    for text in test_texts:
        warning_level = generator._analyze_text_warning_level(text)
        analysis = generator._analyze_environmental_text(text)
        
        print(f"æ–‡æœ¬: {text}")
        print(f"è­¦ç¤ºç­‰çº§: {warning_level}/5")
        print(f"æ£€æµ‹ä¸»é¢˜: {analysis['detected_themes']}")
        print(f"ä¸¥é‡æ€§æŒ‡æ ‡: {analysis['severity_indicators']}")
        print(f"ç¯å¢ƒå½±å“: {analysis['environmental_impact']}")
        print("-" * 50)

if __name__ == "__main__":
    print("ğŸŒ è‡ªç„¶è¯­è¨€å›¾åƒç”ŸæˆåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_prompt_enhancement()
        test_text_analysis()
        success = test_natural_language_generation()
        
        if success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è‡ªç„¶è¯­è¨€å›¾åƒç”ŸæˆåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
        else:
            print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()