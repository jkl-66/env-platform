#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SD3.5æ¨¡å‹ç¦»çº¿ä¸‹è½½æŒ‡å—å’Œå·¥å…·
å½“ç½‘ç»œè¿æ¥æœ‰é—®é¢˜æ—¶çš„è§£å†³æ–¹æ¡ˆ
"""

import os
import shutil
import logging
from pathlib import Path
import json

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class OfflineDownloadGuide:
    def __init__(self):
        self.cache_dir = Path("./cache/huggingface")
        self.model_id = "stabilityai/stable-diffusion-3.5-large-turbo"
        self.model_cache_path = self.cache_dir / "models--stabilityai--stable-diffusion-3.5-large-turbo"
        
        # æ–‡ä»¶ä¸‹è½½é“¾æ¥ï¼ˆå¤šä¸ªé•œåƒæºï¼‰
        self.download_links = {
            "hf-mirror.com": "https://hf-mirror.com/stabilityai/stable-diffusion-3.5-large-turbo/tree/main",
            "huggingface.co": "https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo/tree/main",
            "modelscope.cn": "https://modelscope.cn/models/AI-ModelScope/stable-diffusion-3.5-large-turbo"
        }
        
        # å¿…éœ€çš„æ–‡ä»¶åˆ—è¡¨å’Œå¤§å°ï¼ˆä¼°ç®—ï¼‰
        self.required_files = {
            "model_index.json": "1KB",
            "scheduler/scheduler_config.json": "1KB",
            "text_encoder/config.json": "2KB",
            "text_encoder/model.safetensors": "246MB",
            "text_encoder_2/config.json": "1KB", 
            "text_encoder_2/model.safetensors": "5.1GB",
            "text_encoder_3/config.json": "1KB",
            "text_encoder_3/model.safetensors": "4.7GB",
            "tokenizer/tokenizer_config.json": "2KB",
            "tokenizer/tokenizer.json": "17MB",
            "tokenizer_2/tokenizer_config.json": "1KB",
            "tokenizer_2/tokenizer.json": "2.4MB",
            "tokenizer_3/tokenizer_config.json": "1KB",
            "tokenizer_3/tokenizer.json": "587KB",
            "transformer/config.json": "1KB",
            "transformer/diffusion_pytorch_model-00001-of-00002.safetensors": "4.9GB",
            "transformer/diffusion_pytorch_model-00002-of-00002.safetensors": "4.9GB",
            "transformer/diffusion_pytorch_model.safetensors.index.json": "25KB",
            "vae/config.json": "1KB",
            "vae/diffusion_pytorch_model.safetensors": "335MB"
        }
    
    def print_download_guide(self):
        """æ‰“å°ä¸‹è½½æŒ‡å—"""
        print("="*80)
        print("ğŸ”§ SD3.5æ¨¡å‹ç¦»çº¿ä¸‹è½½æŒ‡å—")
        print("="*80)
        print()
        
        print("ğŸ“‹ æ–¹æ¡ˆä¸€ï¼šæ‰‹åŠ¨ä¸‹è½½ï¼ˆæ¨èï¼‰")
        print("-" * 40)
        print("1. æ‰“å¼€ä»¥ä¸‹ä»»ä¸€ç½‘ç«™ï¼ˆå»ºè®®æŒ‰é¡ºåºå°è¯•ï¼‰ï¼š")
        for name, url in self.download_links.items():
            print(f"   â€¢ {name}: {url}")
        print()
        
        print("2. ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•ï¼š")
        print(f"   ç›®æ ‡ç›®å½•: {self.model_cache_path / 'snapshots' / 'ec07796fc06b096cc56de9762974a28f4c632eda'}")
        print()
        
        # æŒ‰ç›®å½•åˆ†ç»„æ˜¾ç¤ºæ–‡ä»¶
        dirs = {}
        for file_path, size in self.required_files.items():
            dir_name = str(Path(file_path).parent) if '/' in file_path else '.'
            if dir_name not in dirs:
                dirs[dir_name] = []
            dirs[dir_name].append((Path(file_path).name, size))
        
        for dir_name, files in sorted(dirs.items()):
            if dir_name == '.':
                print("   ğŸ“ æ ¹ç›®å½•:")
            else:
                print(f"   ğŸ“ {dir_name}/:")
            
            for filename, size in files:
                print(f"      â€¢ {filename} ({size})")
            print()
        
        total_size = "çº¦20GB"
        print(f"   ğŸ’¾ æ€»å¤§å°: {total_size}")
        print()
        
        print("ğŸ“‹ æ–¹æ¡ˆäºŒï¼šä½¿ç”¨ä¸‹è½½å·¥å…·")
        print("-" * 40)
        print("1. å®‰è£…git-lfs:")
        print("   git lfs install")
        print()
        print("2. å…‹éš†ä»“åº“:")
        print("   git clone https://hf-mirror.com/stabilityai/stable-diffusion-3.5-large-turbo")
        print("   æˆ–")
        print("   git clone https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo")
        print()
        
        print("ğŸ“‹ æ–¹æ¡ˆä¸‰ï¼šä½¿ç”¨huggingface-hub")
        print("-" * 40)
        print("1. å®‰è£…ä¾èµ–:")
        print("   pip install huggingface-hub")
        print()
        print("2. è®¾ç½®é•œåƒï¼ˆå¯é€‰ï¼‰:")
        print("   export HF_ENDPOINT=https://hf-mirror.com")
        print()
        print("3. ä¸‹è½½æ¨¡å‹:")
        print("   python -c \"from huggingface_hub import snapshot_download; snapshot_download('stabilityai/stable-diffusion-3.5-large-turbo', local_dir='./model')\"")
        print()
        
        print("ğŸ“‹ æ–¹æ¡ˆå››ï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹")
        print("-" * 40)
        print("å¦‚æœæ‚¨å·²ç»æœ‰å…¶ä»–SD3.5æ¨¡å‹æ–‡ä»¶ï¼Œå¯ä»¥ï¼š")
        print("1. å°†æ¨¡å‹æ–‡ä»¶å¤åˆ¶åˆ°ç¼“å­˜ç›®å½•")
        print("2. è¿è¡Œ python setup_local_model.py æ¥é…ç½®")
        print()
    
    def create_directory_structure(self):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        commit_hash = "ec07796fc06b096cc56de9762974a28f4c632eda"
        snapshot_dir = self.model_cache_path / "snapshots" / commit_hash
        
        # åˆ›å»ºæ‰€æœ‰å¿…éœ€çš„ç›®å½•
        dirs_to_create = set()
        for file_path in self.required_files.keys():
            if '/' in file_path:
                dir_path = snapshot_dir / Path(file_path).parent
                dirs_to_create.add(dir_path)
        
        for dir_path in dirs_to_create:
            dir_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_path.relative_to(self.cache_dir)}")
        
        return snapshot_dir
    
    def create_download_script(self):
        """åˆ›å»ºä¸‹è½½è„šæœ¬"""
        script_content = '''#!/bin/bash
# SD3.5æ¨¡å‹ä¸‹è½½è„šæœ¬

echo "å¼€å§‹ä¸‹è½½SD3.5æ¨¡å‹æ–‡ä»¶..."

# è®¾ç½®å˜é‡
MODEL_DIR="./cache/huggingface/models--stabilityai--stable-diffusion-3.5-large-turbo/snapshots/ec07796fc06b096cc56de9762974a28f4c632eda"
BASE_URL="https://hf-mirror.com/stabilityai/stable-diffusion-3.5-large-turbo/resolve/main"

# åˆ›å»ºç›®å½•
mkdir -p "$MODEL_DIR/scheduler"
mkdir -p "$MODEL_DIR/text_encoder"
mkdir -p "$MODEL_DIR/text_encoder_2"
mkdir -p "$MODEL_DIR/text_encoder_3"
mkdir -p "$MODEL_DIR/tokenizer"
mkdir -p "$MODEL_DIR/tokenizer_2"
mkdir -p "$MODEL_DIR/tokenizer_3"
mkdir -p "$MODEL_DIR/transformer"
mkdir -p "$MODEL_DIR/vae"

# ä¸‹è½½å‡½æ•°
download_file() {
    local file_path="$1"
    local url="$BASE_URL/$file_path"
    local output="$MODEL_DIR/$file_path"
    
    echo "ä¸‹è½½: $file_path"
    curl -L -o "$output" "$url" || wget -O "$output" "$url"
    
    if [ $? -eq 0 ]; then
        echo "âœ… $file_path ä¸‹è½½å®Œæˆ"
    else
        echo "âŒ $file_path ä¸‹è½½å¤±è´¥"
    fi
}

# ä¸‹è½½æ‰€æœ‰æ–‡ä»¶
download_file "model_index.json"
download_file "scheduler/scheduler_config.json"
download_file "text_encoder/config.json"
download_file "text_encoder/model.safetensors"
download_file "text_encoder_2/config.json"
download_file "text_encoder_2/model.safetensors"
download_file "text_encoder_3/config.json"
download_file "text_encoder_3/model.safetensors"
download_file "tokenizer/tokenizer_config.json"
download_file "tokenizer/tokenizer.json"
download_file "tokenizer_2/tokenizer_config.json"
download_file "tokenizer_2/tokenizer.json"
download_file "tokenizer_3/tokenizer_config.json"
download_file "tokenizer_3/tokenizer.json"
download_file "transformer/config.json"
download_file "transformer/diffusion_pytorch_model-00001-of-00002.safetensors"
download_file "transformer/diffusion_pytorch_model-00002-of-00002.safetensors"
download_file "transformer/diffusion_pytorch_model.safetensors.index.json"
download_file "vae/config.json"
download_file "vae/diffusion_pytorch_model.safetensors"

echo "ä¸‹è½½å®Œæˆï¼"
'''
        
        script_path = Path("download_sd35.sh")
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        # åˆ›å»ºWindowsæ‰¹å¤„ç†æ–‡ä»¶
        bat_content = '''@echo off
echo å¼€å§‹ä¸‹è½½SD3.5æ¨¡å‹æ–‡ä»¶...

set MODEL_DIR=.\cache\huggingface\models--stabilityai--stable-diffusion-3.5-large-turbo\snapshots\ec07796fc06b096cc56de9762974a28f4c632eda
set BASE_URL=https://hf-mirror.com/stabilityai/stable-diffusion-3.5-large-turbo/resolve/main

REM åˆ›å»ºç›®å½•
mkdir "%MODEL_DIR%\scheduler" 2>nul
mkdir "%MODEL_DIR%\text_encoder" 2>nul
mkdir "%MODEL_DIR%\text_encoder_2" 2>nul
mkdir "%MODEL_DIR%\text_encoder_3" 2>nul
mkdir "%MODEL_DIR%\tokenizer" 2>nul
mkdir "%MODEL_DIR%\tokenizer_2" 2>nul
mkdir "%MODEL_DIR%\tokenizer_3" 2>nul
mkdir "%MODEL_DIR%\transformer" 2>nul
mkdir "%MODEL_DIR%\vae" 2>nul

REM ä¸‹è½½æ–‡ä»¶ï¼ˆéœ€è¦å®‰è£…curlæˆ–wgetï¼‰
echo è¯·æ‰‹åŠ¨ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•ï¼š
echo.
echo æ ¹ç›®å½• (%MODEL_DIR%):
echo   - model_index.json
echo.
echo schedulerç›®å½•:
echo   - scheduler_config.json
echo.
echo text_encoderç›®å½•:
echo   - config.json
echo   - model.safetensors
echo.
echo text_encoder_2ç›®å½•:
echo   - config.json
echo   - model.safetensors
echo.
echo text_encoder_3ç›®å½•:
echo   - config.json
echo   - model.safetensors
echo.
echo tokenizerç›®å½•:
echo   - tokenizer_config.json
echo   - tokenizer.json
echo.
echo tokenizer_2ç›®å½•:
echo   - tokenizer_config.json
echo   - tokenizer.json
echo.
echo tokenizer_3ç›®å½•:
echo   - tokenizer_config.json
echo   - tokenizer.json
echo.
echo transformerç›®å½•:
echo   - config.json
echo   - diffusion_pytorch_model-00001-of-00002.safetensors
echo   - diffusion_pytorch_model-00002-of-00002.safetensors
echo   - diffusion_pytorch_model.safetensors.index.json
echo.
echo vaeç›®å½•:
echo   - config.json
echo   - diffusion_pytorch_model.safetensors
echo.
echo ä»ä»¥ä¸‹åœ°å€ä¸‹è½½: %BASE_URL%/[æ–‡ä»¶è·¯å¾„]
echo.
pause
'''
        
        bat_path = Path("download_sd35.bat")
        with open(bat_path, 'w', encoding='gbk') as f:
            f.write(bat_content)
        
        logger.info(f"âœ… ä¸‹è½½è„šæœ¬å·²åˆ›å»º: {script_path.name} å’Œ {bat_path.name}")
    
    def check_existing_files(self):
        """æ£€æŸ¥å·²å­˜åœ¨çš„æ–‡ä»¶"""
        logger.info("ğŸ” æ£€æŸ¥ç°æœ‰æ–‡ä»¶...")
        
        snapshots_dir = self.model_cache_path / "snapshots"
        if not snapshots_dir.exists():
            logger.info("ğŸ“ snapshotsç›®å½•ä¸å­˜åœ¨ï¼Œéœ€è¦ä¸‹è½½æ‰€æœ‰æ–‡ä»¶")
            return []
        
        # æ‰¾åˆ°snapshotç›®å½•
        snapshot_dirs = [d for d in snapshots_dir.iterdir() if d.is_dir()]
        if not snapshot_dirs:
            logger.info("ğŸ“ æœªæ‰¾åˆ°snapshotç›®å½•ï¼Œéœ€è¦ä¸‹è½½æ‰€æœ‰æ–‡ä»¶")
            return []
        
        snapshot_dir = snapshot_dirs[0]
        existing_files = []
        
        for file_path in self.required_files.keys():
            full_path = snapshot_dir / file_path
            if full_path.exists() and full_path.stat().st_size > 0:
                existing_files.append(file_path)
        
        if existing_files:
            logger.info(f"âœ… æ‰¾åˆ° {len(existing_files)} ä¸ªç°æœ‰æ–‡ä»¶")
            missing_files = set(self.required_files.keys()) - set(existing_files)
            if missing_files:
                logger.info(f"âŒ ç¼ºå°‘ {len(missing_files)} ä¸ªæ–‡ä»¶:")
                for file_path in sorted(missing_files):
                    logger.info(f"   â€¢ {file_path}")
        else:
            logger.info("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆæ–‡ä»¶")
        
        return existing_files
    
    def run_offline_guide(self):
        """è¿è¡Œç¦»çº¿æŒ‡å—"""
        logger.info("ğŸ”§ SD3.5æ¨¡å‹ç¦»çº¿ä¸‹è½½æŒ‡å—")
        
        # æ£€æŸ¥ç°æœ‰æ–‡ä»¶
        existing_files = self.check_existing_files()
        
        # åˆ›å»ºç›®å½•ç»“æ„
        snapshot_dir = self.create_directory_structure()
        logger.info(f"ğŸ“ ç›®æ ‡ç›®å½•: {snapshot_dir}")
        
        # åˆ›å»ºä¸‹è½½è„šæœ¬
        self.create_download_script()
        
        # æ‰“å°æŒ‡å—
        self.print_download_guide()
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    guide = OfflineDownloadGuide()
    guide.run_offline_guide()
    
    print("\n" + "="*80)
    print("ğŸ“ æ€»ç»“")
    print("="*80)
    print("ç”±äºç½‘ç»œè¿æ¥é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š")
    print()
    print("ğŸ¥‡ æœ€ä½³æ–¹æ¡ˆ: æ‰‹åŠ¨ä¸‹è½½")
    print("   1. è®¿é—® https://hf-mirror.com/stabilityai/stable-diffusion-3.5-large-turbo")
    print("   2. ä¸‹è½½æ‰€æœ‰å¿…éœ€æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•")
    print("   3. è¿è¡Œ python test_sd35_model.py éªŒè¯")
    print()
    print("ğŸ¥ˆ å¤‡é€‰æ–¹æ¡ˆ: ä½¿ç”¨VPN + è‡ªåŠ¨ä¸‹è½½")
    print("   1. è¿æ¥VPN")
    print("   2. è¿è¡Œ python download_with_china_mirror.py")
    print()
    print("ğŸ¥‰ å…¶ä»–æ–¹æ¡ˆ: ä½¿ç”¨gitæˆ–huggingface-hub")
    print("   è¯¦è§ä¸Šæ–¹æŒ‡å—")
    print()
    print("ğŸ“ ç›®æ ‡ç›®å½•å·²åˆ›å»ºï¼Œå¯ä»¥å¼€å§‹æ‰‹åŠ¨ä¸‹è½½æ–‡ä»¶")
    print("="*80)

if __name__ == "__main__":
    main()