#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¯å¢ƒä¿æŠ¤è­¦ç¤ºå›¾åƒç”Ÿæˆå™¨

åŸºäº Stable Diffusion 3.5 Large Turbo æ¨¡å‹
æ”¯æŒç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥ï¼Œç”Ÿæˆç¯å¢ƒä¿æŠ¤è­¦ç¤ºæ„ä¹‰çš„å›¾åƒ
"""

import os
import sys
import torch
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple
from PIL import Image
import numpy as np

try:
    from diffusers import StableDiffusion3Pipeline
    import transformers
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…: {e}")
    print("è¯·è¿è¡Œ: pip install diffusers transformers torch accelerate")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnvironmentalImageGenerator:
    """ç¯å¢ƒä¿æŠ¤è­¦ç¤ºå›¾åƒç”Ÿæˆå™¨"""
    
    def __init__(self, 
                 model_id: str = "stabilityai/stable-diffusion-3.5-large-turbo",
                 device: Optional[str] = None,
                 cache_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–ç¯å¢ƒå›¾åƒç”Ÿæˆå™¨
        
        Args:
            model_id: Hugging Face æ¨¡å‹ID
            device: è®¡ç®—è®¾å¤‡ (cuda/cpu)ï¼ŒNoneæ—¶è‡ªåŠ¨æ£€æµ‹
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•
        """
        self.model_id = model_id
        self.device = self._setup_device(device)
        self.cache_dir = cache_dir or str(Path.cwd() / "cache" / "huggingface")
        
        # è®¾ç½®Hugging Faceç¯å¢ƒ
        self._setup_huggingface_env()
        
        # åˆå§‹åŒ–ç®¡é“
        self.pipeline = None
        self.is_loaded = False
        
        # ç¯å¢ƒä¿æŠ¤æç¤ºè¯æ¨¡æ¿
        self.environmental_prompts = self._load_environmental_prompts()
        
        logger.info(f"ç¯å¢ƒå›¾åƒç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: {model_id}, è®¾å¤‡: {self.device}")
    
    def _setup_device(self, device: Optional[str]) -> str:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if device:
            return device
        
        if torch.cuda.is_available():
            device = "cuda"
            logger.info(f"æ£€æµ‹åˆ°CUDAè®¾å¤‡: {torch.cuda.get_device_name()}")
        else:
            device = "cpu"
            logger.warning("æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œä½¿ç”¨CPUï¼ˆç”Ÿæˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        
        return device
    
    def _setup_huggingface_env(self):
        """è®¾ç½®Hugging Faceç¯å¢ƒå˜é‡"""
        # è®¾ç½®ç¼“å­˜ç›®å½•
        cache_path = Path(self.cache_dir)
        cache_path.mkdir(parents=True, exist_ok=True)
        
        os.environ['HF_HOME'] = str(cache_path)
        os.environ['TRANSFORMERS_CACHE'] = str(cache_path)
        os.environ['HF_HUB_CACHE'] = str(cache_path)
        
        # è®¾ç½®é•œåƒï¼ˆå¯é€‰ï¼‰
        # os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
        
        logger.info(f"Hugging Faceç¼“å­˜ç›®å½•: {cache_path}")
    
    def _load_environmental_prompts(self) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½ç¯å¢ƒä¿æŠ¤æç¤ºè¯æ¨¡æ¿"""
        return {
            "air_pollution": {
                "base_prompt": "industrial air pollution, smoggy city skyline, thick smoke from factories, poor air quality, environmental warning",
                "keywords": ["pollution", "smog", "factory", "smoke", "air quality"],
                "style_suffix": "dramatic lighting, high contrast, warning atmosphere"
            },
            "water_pollution": {
                "base_prompt": "polluted river with industrial waste, contaminated water, dead fish, environmental disaster",
                "keywords": ["water pollution", "contaminated", "industrial waste", "toxic"],
                "style_suffix": "dark tones, environmental crisis, documentary style"
            },
            "deforestation": {
                "base_prompt": "massive deforestation, cut down trees, environmental destruction, loss of biodiversity",
                "keywords": ["deforestation", "logging", "forest destruction", "habitat loss"],
                "style_suffix": "before and after contrast, environmental impact"
            },
            "climate_change": {
                "base_prompt": "effects of climate change, melting glaciers, rising sea levels, extreme weather",
                "keywords": ["climate change", "global warming", "melting ice", "sea level rise"],
                "style_suffix": "dramatic environmental change, scientific documentation"
            },
            "plastic_pollution": {
                "base_prompt": "ocean plastic pollution, marine life affected by plastic waste, environmental crisis",
                "keywords": ["plastic pollution", "ocean waste", "marine life", "microplastics"],
                "style_suffix": "underwater scene, environmental awareness"
            },
            "renewable_energy": {
                "base_prompt": "renewable energy solutions, solar panels, wind turbines, clean environment, sustainable future",
                "keywords": ["renewable energy", "solar power", "wind energy", "sustainability"],
                "style_suffix": "bright, hopeful, clean technology, positive environmental message"
            }
        }
    
    def load_model(self) -> bool:
        """åŠ è½½Stable Diffusionæ¨¡å‹"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_id}")
            
            self.pipeline = StableDiffusion3Pipeline.from_pretrained(
                self.model_id,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                cache_dir=self.cache_dir,
                use_safetensors=True
            )
            
            # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            self.pipeline = self.pipeline.to(self.device)
            
            # å¯ç”¨å†…å­˜ä¼˜åŒ–
            if self.device == "cuda":
                self.pipeline.enable_model_cpu_offload()
                self.pipeline.enable_attention_slicing()
            
            self.is_loaded = True
            logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _enhance_environmental_prompt(self, user_input: str, category: Optional[str] = None) -> str:
        """å¢å¼ºç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€æè¿°
            category: ç¯å¢ƒç±»åˆ« (å¯é€‰)
            
        Returns:
            å¢å¼ºåçš„æç¤ºè¯
        """
        # æ£€æµ‹ç¯å¢ƒç±»åˆ«
        if not category:
            category = self._detect_environmental_category(user_input)
        
        # è·å–å¯¹åº”çš„æç¤ºè¯æ¨¡æ¿
        template = self.environmental_prompts.get(category, {
            "base_prompt": "",
            "style_suffix": "environmental awareness, high quality, detailed"
        })
        
        # æ„å»ºå¢å¼ºæç¤ºè¯
        enhanced_prompt = f"{user_input}, {template['base_prompt']}, {template['style_suffix']}"
        
        # æ·»åŠ è´¨é‡å’Œé£æ ¼æè¿°
        quality_terms = "high quality, detailed, professional photography, environmental documentary style, 4k resolution"
        
        final_prompt = f"{enhanced_prompt}, {quality_terms}"
        
        logger.info(f"åŸå§‹è¾“å…¥: {user_input}")
        logger.info(f"å¢å¼ºæç¤ºè¯: {final_prompt}")
        
        return final_prompt
    
    def enhance_prompt(self, user_input: str, category: Optional[str] = None) -> str:
        """å¢å¼ºæç¤ºè¯çš„å…¬å…±æ¥å£"""
        return self._enhance_environmental_prompt(user_input, category)
    
    def _detect_environmental_category(self, user_input: str) -> str:
        """æ£€æµ‹ç”¨æˆ·è¾“å…¥çš„ç¯å¢ƒç±»åˆ«"""
        user_input_lower = user_input.lower()
        
        for category, template in self.environmental_prompts.items():
            keywords = template.get("keywords", [])
            for keyword in keywords:
                if keyword.lower() in user_input_lower:
                    return category
        
        # é»˜è®¤è¿”å›é€šç”¨ç¯å¢ƒç±»åˆ«
        return "air_pollution"
    
    def generate_image(self, 
                      user_input: Optional[str] = None,
                      prompt: Optional[str] = None, 
                      num_images: int = 1,
                      guidance_scale: float = 7.5,
                      num_inference_steps: int = 28,
                      height: int = 1024,
                      width: int = 1024,
                      seed: Optional[int] = None) -> Dict[str, Any]:
        """ç”Ÿæˆå›¾åƒ
        
        Args:
            user_input: ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥ (ä¼˜å…ˆä½¿ç”¨)
            prompt: ç›´æ¥æç¤ºè¯ (å½“user_inputä¸ºNoneæ—¶ä½¿ç”¨)
            num_images: ç”Ÿæˆå›¾åƒæ•°é‡
            guidance_scale: å¼•å¯¼å¼ºåº¦
            num_inference_steps: æ¨ç†æ­¥æ•°
            height: å›¾åƒé«˜åº¦
            width: å›¾åƒå®½åº¦
            seed: éšæœºç§å­
            
        Returns:
            åŒ…å«ç”Ÿæˆç»“æœçš„å­—å…¸
        """
        # è‡ªåŠ¨åŠ è½½æ¨¡å‹
        if not self.is_loaded:
            if not self.load_model():
                return {
                    "success": False,
                    "error": "æ¨¡å‹åŠ è½½å¤±è´¥",
                    "image_paths": [],
                    "images": []
                }
        
        # å¤„ç†è¾“å…¥å‚æ•°
        if user_input:
            final_prompt = self._enhance_environmental_prompt(user_input)
        elif prompt:
            final_prompt = prompt
        else:
            return {
                "success": False,
                "error": "å¿…é¡»æä¾› user_input æˆ– prompt å‚æ•°",
                "image_paths": [],
                "images": []
            }
        
        try:
            # è®¾ç½®éšæœºç§å­
            if seed is not None:
                torch.manual_seed(seed)
                if torch.cuda.is_available():
                    torch.cuda.manual_seed(seed)
            
            logger.info(f"å¼€å§‹ç”Ÿæˆå›¾åƒ - æ•°é‡: {num_images}, å°ºå¯¸: {width}x{height}")
            logger.info(f"ä½¿ç”¨æç¤ºè¯: {final_prompt}")
            
            start_time = datetime.now()
            
            # ç”Ÿæˆå›¾åƒ
            with torch.autocast(self.device):
                result = self.pipeline(
                    prompt=final_prompt,
                    num_images_per_prompt=num_images,
                    guidance_scale=guidance_scale,
                    num_inference_steps=num_inference_steps,
                    height=height,
                    width=width
                )
            
            end_time = datetime.now()
            generation_time = (end_time - start_time).total_seconds()
            
            images = result.images
            logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(images)} å¼ å›¾åƒï¼Œè€—æ—¶ {generation_time:.2f} ç§’")
            
            # ä¿å­˜å›¾åƒ
            output_dir = "outputs/environmental_images"
            saved_paths = self.save_images(images, user_input or final_prompt, output_dir)
            
            return {
                "success": True,
                "images": images,
                "image_paths": saved_paths,
                "output_path": output_dir,
                "prompt": final_prompt,
                "generation_time": generation_time,
                "parameters": {
                    "num_images": num_images,
                    "guidance_scale": guidance_scale,
                    "num_inference_steps": num_inference_steps,
                    "height": height,
                    "width": width,
                    "seed": seed
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "image_paths": [],
                "images": []
            }
    
    def save_images(self, 
                   images: List[Image.Image], 
                   prompt: str,
                   output_dir: str = "outputs/environmental_images") -> List[str]:
        """ä¿å­˜ç”Ÿæˆçš„å›¾åƒ
        
        Args:
            images: å›¾åƒåˆ—è¡¨
            prompt: åŸå§‹æç¤ºè¯
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if not images:
            return []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_prompt = "".join(c for c in prompt[:20] if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_prompt = safe_prompt.replace(" ", "_")
        
        saved_paths = []
        
        for i, image in enumerate(images, 1):
            filename = f"{safe_prompt}_{timestamp}_{i}.png"
            file_path = output_path / filename
            
            image.save(file_path, "PNG")
            saved_paths.append(str(file_path))
            
            logger.info(f"å›¾åƒå·²ä¿å­˜: {file_path}")
        
        return saved_paths
    
    def generate_and_save(self, 
                         user_input: str,
                         category: Optional[str] = None,
                         num_images: int = 1,
                         output_dir: str = "outputs/environmental_images",
                         **generation_kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå¹¶ä¿å­˜å›¾åƒçš„ä¾¿æ·æ–¹æ³•
        
        Args:
            user_input: ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥
            category: ç¯å¢ƒç±»åˆ«
            num_images: ç”Ÿæˆå›¾åƒæ•°é‡
            output_dir: è¾“å‡ºç›®å½•
            **generation_kwargs: å…¶ä»–ç”Ÿæˆå‚æ•°
            
        Returns:
            ç”Ÿæˆç»“æœä¿¡æ¯
        """
        # å¢å¼ºæç¤ºè¯
        enhanced_prompt = self.enhance_prompt(user_input, category)
        
        # ç”Ÿæˆå›¾åƒ
        images = self.generate_image(
            prompt=enhanced_prompt,
            num_images=num_images,
            **generation_kwargs
        )
        
        if not images:
            return {
                "success": False,
                "error": "å›¾åƒç”Ÿæˆå¤±è´¥",
                "user_input": user_input,
                "enhanced_prompt": enhanced_prompt
            }
        
        # ä¿å­˜å›¾åƒ
        saved_paths = self.save_images(images, user_input, output_dir)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "success": True,
            "user_input": user_input,
            "enhanced_prompt": enhanced_prompt,
            "category": category or self._detect_environmental_category(user_input),
            "num_images": len(images),
            "saved_files": saved_paths,
            "timestamp": datetime.now().isoformat(),
            "model_id": self.model_id,
            "device": self.device
        }
        
        # ä¿å­˜ç”ŸæˆæŠ¥å‘Š
        self._save_generation_report(report, output_dir)
        
        return report
    
    def _save_generation_report(self, report: Dict[str, Any], output_dir: str):
        """ä¿å­˜ç”ŸæˆæŠ¥å‘Š"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = output_path / f"generation_report_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ç”ŸæˆæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def list_environmental_categories(self) -> Dict[str, str]:
        """åˆ—å‡ºæ‰€æœ‰ç¯å¢ƒç±»åˆ«"""
        return {
            category: template["base_prompt"]
            for category, template in self.environmental_prompts.items()
        }
    
    def update_environmental_prompts(self, new_prompts: Dict[str, Dict[str, Any]]):
        """æ›´æ–°ç¯å¢ƒæç¤ºè¯æ¨¡æ¿
        
        Args:
            new_prompts: æ–°çš„æç¤ºè¯æ¨¡æ¿å­—å…¸
        """
        self.environmental_prompts.update(new_prompts)
        logger.info("ç¯å¢ƒæç¤ºè¯æ¨¡æ¿å·²æ›´æ–°")
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "model_id": self.model_id,
            "device": self.device,
            "is_loaded": self.is_loaded,
            "cache_dir": self.cache_dir,
            "environmental_categories": list(self.environmental_prompts.keys())
        }

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºåŸºæœ¬ç”¨æ³•"""
    print("ğŸŒ ç¯å¢ƒä¿æŠ¤è­¦ç¤ºå›¾åƒç”Ÿæˆå™¨")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = EnvironmentalImageGenerator()
    
    # åŠ è½½æ¨¡å‹
    if not generator.load_model():
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    # äº¤äº’å¼ç”Ÿæˆ
    while True:
        try:
            print("\nè¯·è¾“å…¥æ‚¨æƒ³è¦ç”Ÿæˆçš„ç¯å¢ƒåœºæ™¯æè¿°ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰:")
            user_input = input("> ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            if not user_input:
                print("âŒ è¾“å…¥ä¸èƒ½ä¸ºç©º")
                continue
            
            print(f"\nğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾åƒ: {user_input}")
            
            # ç”Ÿæˆå¹¶ä¿å­˜å›¾åƒ
            result = generator.generate_and_save(
                user_input=user_input,
                num_images=1
            )
            
            if result["success"]:
                print(f"âœ… ç”ŸæˆæˆåŠŸï¼")
                print(f"ğŸ“ ä¿å­˜ä½ç½®: {result['saved_files'][0]}")
                print(f"ğŸ·ï¸  ç±»åˆ«: {result['category']}")
            else:
                print(f"âŒ ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
    
    print("\næ„Ÿè°¢ä½¿ç”¨ç¯å¢ƒä¿æŠ¤è­¦ç¤ºå›¾åƒç”Ÿæˆå™¨ï¼")

if __name__ == "__main__":
    main()