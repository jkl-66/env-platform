#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“ä¸š Prompt æŸ¥çœ‹å™¨

ä¸“é—¨ç”¨äºæŸ¥çœ‹å’Œåˆ†æ DashScope ç¯å¢ƒå›¾åƒç”Ÿæˆå™¨ç”Ÿæˆçš„ä¸“ä¸š prompt
æ”¯æŒå¤šç§æŸ¥çœ‹æ–¹å¼ï¼šå®æ—¶ç”Ÿæˆã€å†å²è®°å½•æŸ¥çœ‹ã€è¯¦ç»†åˆ†æç­‰
"""

import sys
import os
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dashscope_environmental_generator import DashScopeEnvironmentalGenerator

def view_prompt_only():
    """
    ä»…ç”Ÿæˆå’ŒæŸ¥çœ‹ä¸“ä¸š promptï¼Œä¸ç”Ÿæˆå›¾åƒ
    """
    print("ğŸ” ä¸“ä¸š Prompt æŸ¥çœ‹å™¨")
    print("=" * 50)
    
    try:
        generator = DashScopeEnvironmentalGenerator()
        
        # æµ‹è¯•è¿æ¥
        print("ğŸ”— æ­£åœ¨æµ‹è¯•è¿æ¥...")
        test_result = generator.test_connection()
        if not test_result["success"]:
            print(f"âŒ è¿æ¥å¤±è´¥: {test_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return
        
        print("âœ… è¿æ¥æˆåŠŸï¼")
        
        while True:
            print("\n" + "=" * 50)
            print("è¯·é€‰æ‹©æ“ä½œ:")
            print("1. ä½¿ç”¨é¢„è®¾æ•°æ®ç”Ÿæˆ prompt")
            print("2. è‡ªå®šä¹‰ç¯å¢ƒæ•°æ®ç”Ÿæˆ prompt")
            print("3. æŸ¥çœ‹å†å²ç”ŸæˆæŠ¥å‘Šä¸­çš„ prompt")
            print("4. æ‰¹é‡ç”Ÿæˆå¤šä¸ªåœºæ™¯çš„ prompt")
            print("5. é€€å‡º")
            
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-5): ").strip()
            
            if choice == "1":
                generate_prompt_with_preset_data(generator)
            elif choice == "2":
                generate_prompt_with_custom_data(generator)
            elif choice == "3":
                view_historical_prompts()
            elif choice == "4":
                batch_generate_prompts(generator)
            elif choice == "5":
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ä¸“ä¸š Prompt æŸ¥çœ‹å™¨ï¼")
        
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

def generate_prompt_with_preset_data(generator):
    """
    ä½¿ç”¨é¢„è®¾æ•°æ®ç”Ÿæˆ prompt
    """
    print("\nğŸ¯ é¢„è®¾ç¤ºä¾‹åœºæ™¯:")
    
    scenarios = {
        "1": {
            "name": "è½»åº¦ç©ºæ°”æ±¡æŸ“",
            "data": {"air_quality_index": 120, "carbon_emission": 300},
            "description": "åŸå¸‚è½»åº¦é›¾éœ¾ï¼Œèƒ½è§åº¦ç¨æœ‰ä¸‹é™",
            "audience": "general"
        },
        "2": {
            "name": "ä¸­åº¦å·¥ä¸šæ±¡æŸ“",
            "data": {"carbon_emission": 800, "air_quality_index": 180, "water_pollution_index": 60},
            "description": "å·¥ä¸šåŒºæ±¡æŸ“ç‰©æ’æ”¾ï¼Œå½±å“å‘¨è¾¹ç¯å¢ƒ",
            "audience": "educators"
        },
        "3": {
            "name": "ä¸¥é‡ç¯å¢ƒå±æœº",
            "data": {"carbon_emission": 2500, "air_quality_index": 350, "water_pollution_index": 95, "deforestation_rate": 25000},
            "description": "å¤šé‡ç¯å¢ƒé—®é¢˜å åŠ ï¼Œç”Ÿæ€ç³»ç»Ÿé¢ä¸´å´©æºƒ",
            "audience": "students"
        },
        "4": {
            "name": "æµ·æ´‹å¡‘æ–™æ±¡æŸ“",
            "data": {"plastic_waste": 2000, "water_pollution_index": 80},
            "description": "æµ·æ´‹ä¸­å¤§é‡å¡‘æ–™åƒåœ¾ï¼Œæµ·æ´‹ç”Ÿç‰©å—åˆ°ä¸¥é‡å¨èƒ",
            "audience": "parents"
        },
        "5": {
            "name": "å™ªéŸ³æ±¡æŸ“ä¸¥é‡åŒºåŸŸ",
            "data": {"noise_level": 95, "air_quality_index": 140},
            "description": "åŸå¸‚äº¤é€šå’Œå·¥ä¸šå™ªéŸ³ä¸¥é‡è¶…æ ‡",
            "audience": "general"
        }
    }
    
    data_types = generator.get_supported_data_types()
    
    for key, scenario in scenarios.items():
        print(f"  {key}. {scenario['name']} (ç›®æ ‡ç”¨æˆ·: {scenario['audience']})")
        for data_type, value in scenario['data'].items():
            if data_type in data_types:
                data_config = data_types[data_type]
                default_value = data_config.get('default_value', 0)
                deviation = ((value - default_value) / default_value * 100) if default_value > 0 else 0
                status = "âš ï¸ å¼‚å¸¸" if abs(deviation) > 30 else "âœ… æ­£å¸¸"
                print(f"     - {data_config['name']}: {value} {data_config['unit']} (é»˜è®¤: {default_value}, åå·®: {deviation:+.1f}%) {status}")
    
    choice = input("\nè¯·é€‰æ‹©åœºæ™¯ (1-5): ").strip()
    
    if choice in scenarios:
        scenario = scenarios[choice]
        print(f"\nğŸ¤– æ­£åœ¨ä¸º '{scenario['name']}' ç”Ÿæˆä¸“ä¸š prompt...")
        print(f"ğŸ¯ ç›®æ ‡ç”¨æˆ·: {scenario['audience']}")
        
        # åˆ†æç¯å¢ƒæ•°æ®
        analysis = generator._analyze_environmental_data(scenario['data'])
        
        # ç”Ÿæˆä¸“ä¸š prompt
        professional_prompt = generator._generate_professional_prompt(
            scenario['data'],
            scenario['description'],
            scenario['audience']
        )
        
        display_prompt_analysis(scenario, analysis, professional_prompt)
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

def generate_prompt_with_custom_data(generator):
    """
    ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®ç”Ÿæˆ prompt
    """
    print("\nğŸ“ è¯·è¾“å…¥ç¯å¢ƒæ•°æ®:")
    
    data_types = generator.get_supported_data_types()
    environmental_data = {}
    
    print("\nå¯é€‰çš„ç¯å¢ƒæ•°æ®ç±»å‹ (è¾“å…¥æ•°å€¼ï¼Œç•™ç©ºè·³è¿‡):")
    
    for data_type, config in data_types.items():
        while True:
            try:
                value_input = input(f"  {config['name']} ({config['unit']}): ").strip()
                if not value_input:
                    break
                
                value = float(value_input)
                if value < 0:
                    print("    âŒ æ•°å€¼ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
                
                environmental_data[data_type] = value
                break
                
            except ValueError:
                print("    âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    if not environmental_data:
        print("âŒ æœªè¾“å…¥ä»»ä½•ç¯å¢ƒæ•°æ®")
        return
    
    # è·å–ç”¨æˆ·æè¿°
    user_description = input("\nè¯·æè¿°å…·ä½“çš„ç¯å¢ƒæƒ…å†µ (å¯é€‰): ").strip()
    if not user_description:
        user_description = None
    
    # é€‰æ‹©ç›®æ ‡å—ä¼—
    print("\nç›®æ ‡å—ä¼—:")
    audiences = {
        "1": "general",
        "2": "educators", 
        "3": "parents",
        "4": "students"
    }
    
    for key, audience in audiences.items():
        audience_names = {
            "general": "ä¸€èˆ¬å…¬ä¼—",
            "educators": "æ•™è‚²å·¥ä½œè€…",
            "parents": "å®¶é•¿",
            "students": "å­¦ç”Ÿ"
        }
        print(f"  {key}. {audience_names[audience]}")
    
    audience_choice = input("è¯·é€‰æ‹©ç›®æ ‡å—ä¼— (1-4, é»˜è®¤ä¸º1): ").strip() or "1"
    target_audience = audiences.get(audience_choice, "general")
    
    print(f"\nğŸ¤– æ­£åœ¨ç”Ÿæˆä¸“ä¸š prompt...")
    
    # åˆ†æç¯å¢ƒæ•°æ®
    analysis = generator._analyze_environmental_data(environmental_data)
    
    # ç”Ÿæˆä¸“ä¸š prompt
    professional_prompt = generator._generate_professional_prompt(
        environmental_data,
        user_description,
        target_audience
    )
    
    scenario = {
        "name": "è‡ªå®šä¹‰ç¯å¢ƒæ•°æ®",
        "data": environmental_data,
        "description": user_description,
        "audience": target_audience
    }
    
    display_prompt_analysis(scenario, analysis, professional_prompt)

def view_historical_prompts():
    """
    æŸ¥çœ‹å†å²ç”ŸæˆæŠ¥å‘Šä¸­çš„ prompt
    """
    print("\nğŸ“š æŸ¥çœ‹å†å²ç”ŸæˆæŠ¥å‘Š")
    
    reports_dir = Path("outputs/environmental_images")
    if not reports_dir.exists():
        print("âŒ æœªæ‰¾åˆ°å†å²æŠ¥å‘Šç›®å½•")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
    report_files = list(reports_dir.glob("environmental_report_*.json"))
    
    if not report_files:
        print("âŒ æœªæ‰¾åˆ°å†å²æŠ¥å‘Šæ–‡ä»¶")
        return
    
    # æŒ‰æ—¶é—´æ’åº
    report_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    
    print(f"\næ‰¾åˆ° {len(report_files)} ä¸ªå†å²æŠ¥å‘Š:")
    
    for i, report_file in enumerate(report_files[:10], 1):  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ª
        mtime = datetime.fromtimestamp(report_file.stat().st_mtime)
        print(f"  {i}. {report_file.name} ({mtime.strftime('%Y-%m-%d %H:%M:%S')})")
    
    try:
        choice = input("\nè¯·é€‰æ‹©è¦æŸ¥çœ‹çš„æŠ¥å‘Š (1-10): ").strip()
        index = int(choice) - 1
        
        if 0 <= index < min(len(report_files), 10):
            report_file = report_files[index]
            
            with open(report_file, 'r', encoding='utf-8') as f:
                report_data = json.load(f)
            
            display_historical_prompt_analysis(report_data)
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except (ValueError, IndexError):
        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    except Exception as e:
        print(f"âŒ è¯»å–æŠ¥å‘Šæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

def batch_generate_prompts(generator):
    """
    æ‰¹é‡ç”Ÿæˆå¤šä¸ªåœºæ™¯çš„ prompt
    """
    print("\nğŸ”„ æ‰¹é‡ç”Ÿæˆ Prompt")
    
    batch_scenarios = [
        {
            "name": "è½»åº¦æ±¡æŸ“",
            "data": {"air_quality_index": 80, "carbon_emission": 200},
            "description": "è½»å¾®çš„ç©ºæ°”è´¨é‡é—®é¢˜",
            "audience": "general"
        },
        {
            "name": "ä¸­åº¦æ±¡æŸ“",
            "data": {"air_quality_index": 150, "carbon_emission": 600, "water_pollution_index": 50},
            "description": "ä¸­ç­‰ç¨‹åº¦çš„ç¯å¢ƒæ±¡æŸ“",
            "audience": "educators"
        },
        {
            "name": "é‡åº¦æ±¡æŸ“",
            "data": {"air_quality_index": 250, "carbon_emission": 1500, "water_pollution_index": 80},
            "description": "ä¸¥é‡çš„ç¯å¢ƒæ±¡æŸ“é—®é¢˜",
            "audience": "students"
        },
        {
            "name": "æé‡æ±¡æŸ“",
            "data": {"air_quality_index": 400, "carbon_emission": 3000, "water_pollution_index": 95, "deforestation_rate": 30000},
            "description": "æå…¶ä¸¥é‡çš„ç¯å¢ƒå±æœº",
            "audience": "parents"
        }
    ]
    
    print(f"\nå°†ä¸º {len(batch_scenarios)} ä¸ªåœºæ™¯ç”Ÿæˆ prompt:")
    for i, scenario in enumerate(batch_scenarios, 1):
        print(f"  {i}. {scenario['name']}")
    
    confirm = input("\nç¡®è®¤å¼€å§‹æ‰¹é‡ç”Ÿæˆï¼Ÿ(y/N): ").strip().lower()
    if confirm != 'y':
        print("âŒ å·²å–æ¶ˆæ‰¹é‡ç”Ÿæˆ")
        return
    
    print("\nğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆ...")
    
    for i, scenario in enumerate(batch_scenarios, 1):
        print(f"\n--- åœºæ™¯ {i}: {scenario['name']} ---")
        
        try:
            # åˆ†æç¯å¢ƒæ•°æ®
            analysis = generator._analyze_environmental_data(scenario['data'])
            
            # ç”Ÿæˆä¸“ä¸š prompt
            professional_prompt = generator._generate_professional_prompt(
                scenario['data'],
                scenario['description'],
                scenario['audience']
            )
            
            print(f"âœ… ç”ŸæˆæˆåŠŸ")
            print(f"ğŸ“Š ä¸¥é‡ç¨‹åº¦: {analysis['overall_severity']}")
            print(f"ğŸ“ Prompt (å‰100å­—ç¬¦): {professional_prompt[:100]}...")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
    
    print("\nğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆï¼")

def display_prompt_analysis(scenario, analysis, professional_prompt):
    """
    æ˜¾ç¤º prompt åˆ†æç»“æœ
    """
    print(f"\n" + "=" * 60)
    print(f"ğŸ“‹ åœºæ™¯åˆ†æ: {scenario['name']}")
    print("=" * 60)
    
    # ç¯å¢ƒæ•°æ®
    print("\nğŸ“Š ç¯å¢ƒæ•°æ®:")
    for data_type, value in scenario['data'].items():
        if data_type in analysis['severity_scores']:
            score_info = analysis['severity_scores'][data_type]
            print(f"  â€¢ {score_info['unit']} å‰çš„æ•°å€¼: {value} {score_info['unit']} (ä¸¥é‡ç¨‹åº¦: {score_info['severity']})")
    
    # åˆ†æç»“æœ
    print(f"\nğŸ¯ æ€»ä½“ä¸¥é‡ç¨‹åº¦: {analysis['overall_severity']}")
    
    if analysis['critical_factors']:
        print(f"\nâš ï¸  å…³é”®é—®é¢˜å› ç´  ({len(analysis['critical_factors'])}ä¸ª):")
        for factor in analysis['critical_factors']:
            print(f"  â€¢ {factor['name']}: {factor['value']} {factor['unit']} ({factor['severity']})")
    
    # ç›®æ ‡å—ä¼—å’Œæè¿°
    print(f"\nğŸ‘¥ ç›®æ ‡å—ä¼—: {scenario['audience']}")
    if scenario.get('description'):
        print(f"ğŸ“ ç”¨æˆ·æè¿°: {scenario['description']}")
    
    # å®Œæ•´çš„ä¸“ä¸š prompt
    print(f"\n" + "=" * 60)
    print("ğŸ¤– ç”Ÿæˆçš„ä¸“ä¸š Prompt (å®Œæ•´ç‰ˆ):")
    print("=" * 60)
    print(professional_prompt)
    print("=" * 60)
    
    # Prompt åˆ†æ
    analyze_prompt_content(professional_prompt, scenario['audience'])
    
    # ä¿å­˜é€‰é¡¹
    save_option = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜æ­¤ prompt åˆ°æ–‡ä»¶ï¼Ÿ(y/N): ").strip().lower()
    if save_option == 'y':
        save_prompt_to_file(scenario, analysis, professional_prompt)

def display_historical_prompt_analysis(report_data):
    """
    æ˜¾ç¤ºå†å² prompt åˆ†æ
    """
    print(f"\n" + "=" * 60)
    print(f"ğŸ“‹ å†å²æŠ¥å‘Šåˆ†æ")
    print("=" * 60)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"\nâ° ç”Ÿæˆæ—¶é—´: {report_data.get('timestamp', 'æœªçŸ¥')}")
    print(f"ğŸ¯ ç›®æ ‡å—ä¼—: {report_data.get('target_audience', 'æœªçŸ¥')}")
    print(f"â±ï¸  ç”Ÿæˆè€—æ—¶: {report_data.get('generation_time', 0):.2f} ç§’")
    
    # ä½¿ç”¨çš„æ¨¡å‹
    if 'models_used' in report_data:
        models = report_data['models_used']
        print(f"ğŸ¤– èŠå¤©æ¨¡å‹: {models.get('chat_model', 'æœªçŸ¥')}")
        print(f"ğŸ¨ å›¾åƒæ¨¡å‹: {models.get('image_model', 'æœªçŸ¥')}")
    
    # ç¯å¢ƒæ•°æ®
    if 'environmental_data' in report_data:
        print(f"\nğŸ“Š ç¯å¢ƒæ•°æ®:")
        for data_type, value in report_data['environmental_data'].items():
            print(f"  â€¢ {data_type}: {value}")
    
    # åˆ†æç»“æœ
    if 'analysis' in report_data:
        analysis = report_data['analysis']
        print(f"\nğŸ¯ æ€»ä½“ä¸¥é‡ç¨‹åº¦: {analysis.get('overall_severity', 'æœªçŸ¥')}")
        
        if analysis.get('critical_factors'):
            print(f"\nâš ï¸  å…³é”®é—®é¢˜å› ç´ :")
            for factor in analysis['critical_factors']:
                print(f"  â€¢ {factor.get('name', 'æœªçŸ¥')}: {factor.get('value', 'æœªçŸ¥')} {factor.get('unit', '')}")
    
    # ä¸“ä¸š prompt
    if 'professional_prompt' in report_data:
        print(f"\n" + "=" * 60)
        print("ğŸ¤– ä¸“ä¸š Prompt:")
        print("=" * 60)
        print(report_data['professional_prompt'])
        print("=" * 60)
        
        analyze_prompt_content(report_data['professional_prompt'], report_data.get('target_audience', 'general'))
    
    # ä¿å­˜çš„å›¾åƒè·¯å¾„
    if 'saved_paths' in report_data and report_data['saved_paths']:
        print(f"\nğŸ“ ç”Ÿæˆçš„å›¾åƒ: {report_data['saved_paths'][0]}")

def analyze_prompt_content(prompt, target_audience="general"):
    """
    åˆ†æ prompt å†…å®¹
    """
    print(f"\nğŸ“ˆ Prompt å†…å®¹åˆ†æ:")
    print(f"  â€¢ å­—ç¬¦æ•°: {len(prompt)}")
    print(f"  â€¢ å•è¯æ•°: {len(prompt.split())}")
    print(f"  â€¢ å¥å­æ•°: {prompt.count('.') + prompt.count('!') + prompt.count('?')}")
    print(f"  â€¢ ç›®æ ‡ç”¨æˆ·: {target_audience}")
    
    # æ£€æŸ¥é™åˆ¶æ¡ä»¶
    restrictions_check = {
        "æ— äººç‰©": not any(word in prompt.lower() for word in ['people', 'person', 'human', 'man', 'woman', 'child', 'face']),
        "æ— æ–‡å­—": not any(word in prompt.lower() for word in ['text', 'words', 'letters', 'sign', 'label', 'writing']),
        "ç¯å¢ƒç„¦ç‚¹": any(word in prompt.lower() for word in ['environment', 'nature', 'landscape', 'ecosystem', 'wildlife'])
    }
    
    print(f"\nâœ… é™åˆ¶æ¡ä»¶æ£€æŸ¥:")
    for condition, passed in restrictions_check.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ æœªé€šè¿‡"
        print(f"  â€¢ {condition}: {status}")
    
    # é£æ ¼åˆ†æï¼ˆåŸºäºç›®æ ‡ç”¨æˆ·ï¼‰
    style_keywords = {
        "general": ['realistic', 'professional', 'detailed', 'documentary'],
        "educators": ['educational', 'clear', 'informative', 'scientific'],
        "parents": ['gentle', 'caring', 'soft', 'warm', 'hopeful'],
        "students": ['cartoon', 'animated', 'colorful', 'playful', 'bright']
    }
    
    expected_style = style_keywords.get(target_audience, [])
    found_style_keywords = [kw for kw in expected_style if kw.lower() in prompt.lower()]
    
    print(f"\nğŸ¨ é£æ ¼é€‚é…æ€§ (ç›®æ ‡: {target_audience}):")
    if found_style_keywords:
        print(f"  â€¢ åŒ¹é…çš„é£æ ¼è¯: {', '.join(found_style_keywords)}")
    else:
        print(f"  â€¢ æœªå‘ç°æ˜æ˜¾çš„ç›®æ ‡é£æ ¼è¯æ±‡")
    
    # å…³é”®è¯åˆ†æ
    environmental_keywords = [
        'pollution', 'environmental', 'toxic', 'contaminated', 'emissions', 
        'smog', 'waste', 'degradation', 'crisis', 'damage', 'harmful',
        'industrial', 'factory', 'smoke', 'chemical', 'oil', 'plastic'
    ]
    
    visual_keywords = [
        'dramatic', 'lighting', 'contrast', 'photography', 'realistic',
        'documentary', 'professional', 'high quality', '4k', 'detailed'
    ]
    
    found_env_keywords = [kw for kw in environmental_keywords if kw.lower() in prompt.lower()]
    found_visual_keywords = [kw for kw in visual_keywords if kw.lower() in prompt.lower()]
    
    if found_env_keywords:
        print(f"  â€¢ ç¯å¢ƒå…³é”®è¯: {', '.join(found_env_keywords[:5])}{'...' if len(found_env_keywords) > 5 else ''}")
    
    if found_visual_keywords:
        print(f"  â€¢ è§†è§‰å…³é”®è¯: {', '.join(found_visual_keywords[:5])}{'...' if len(found_visual_keywords) > 5 else ''}")
    
    # æƒ…æ„Ÿå€¾å‘åˆ†æ
    positive_words = ['hope', 'clean', 'clear', 'beautiful', 'pristine', 'healthy']
    negative_words = ['polluted', 'contaminated', 'toxic', 'dangerous', 'harmful', 'dirty']
    
    positive_count = sum(1 for word in positive_words if word.lower() in prompt.lower())
    negative_count = sum(1 for word in negative_words if word.lower() in prompt.lower())
    
    print(f"\nğŸ˜Š æƒ…æ„Ÿå€¾å‘:")
    print(f"  â€¢ ç§¯æè¯æ±‡: {positive_count}ä¸ª")
    print(f"  â€¢ æ¶ˆæè¯æ±‡: {negative_count}ä¸ª")
    
    if negative_count > positive_count:
        print(f"  â€¢ å€¾å‘: è­¦ç¤ºæ€§ (çªå‡ºç¯å¢ƒé—®é¢˜)")
    elif positive_count > negative_count:
        print(f"  â€¢ å€¾å‘: å¸Œæœ›æ€§ (å¼ºè°ƒè§£å†³æ–¹æ¡ˆ)")
    else:
        print(f"  â€¢ å€¾å‘: å¹³è¡¡æ€§ (é—®é¢˜ä¸å¸Œæœ›å¹¶é‡)")

def save_prompt_to_file(scenario, analysis, professional_prompt):
    """
    ä¿å­˜ prompt åˆ°æ–‡ä»¶
    """
    try:
        output_dir = Path("outputs/prompts")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"prompt_{scenario['name'].replace(' ', '_')}_{timestamp}.txt"
        file_path = output_dir / filename
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"åœºæ™¯: {scenario['name']}\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ç›®æ ‡å—ä¼—: {scenario['audience']}\n")
            f.write(f"æ€»ä½“ä¸¥é‡ç¨‹åº¦: {analysis['overall_severity']}\n")
            f.write("\n" + "=" * 50 + "\n")
            f.write("ä¸“ä¸š Prompt:\n")
            f.write("=" * 50 + "\n")
            f.write(professional_prompt)
            f.write("\n\n" + "=" * 50 + "\n")
            f.write("ç¯å¢ƒæ•°æ®:\n")
            for data_type, value in scenario['data'].items():
                f.write(f"  {data_type}: {value}\n")
        
        print(f"âœ… Prompt å·²ä¿å­˜åˆ°: {file_path}")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

def main():
    """
    ä¸»å‡½æ•°
    """
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv('DASHSCOPE_API_KEY'):
        print("âŒ æœªè®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® DASHSCOPE_API_KEY")
        return
    
    view_prompt_only()

if __name__ == "__main__":
    main()