#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…ç†ä¸å®Œæ•´çš„æ¨¡å‹ç¼“å­˜å¹¶é‡æ–°ä¸‹è½½SD3.5
"""

import os
import shutil
import logging
from pathlib import Path
from huggingface_hub import snapshot_download
import time

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ModelCacheCleaner:
    def __init__(self):
        self.cache_dir = Path("./cache/huggingface")
        self.model_id = "stabilityai/stable-diffusion-3.5-large-turbo"
        self.model_cache_path = self.cache_dir / "models--stabilityai--stable-diffusion-3.5-large-turbo"
        
    def check_incomplete_files(self):
        """æ£€æŸ¥ä¸å®Œæ•´çš„æ–‡ä»¶"""
        logger.info("ğŸ” æ£€æŸ¥ä¸å®Œæ•´çš„æ–‡ä»¶...")
        
        if not self.model_cache_path.exists():
            logger.info("âŒ æ¨¡å‹ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
            return []
        
        blobs_dir = self.model_cache_path / "blobs"
        if not blobs_dir.exists():
            logger.info("âŒ blobsç›®å½•ä¸å­˜åœ¨")
            return []
        
        incomplete_files = list(blobs_dir.glob("*.incomplete"))
        
        if incomplete_files:
            logger.info(f"âš ï¸  å‘ç° {len(incomplete_files)} ä¸ªä¸å®Œæ•´æ–‡ä»¶:")
            for file in incomplete_files:
                logger.info(f"   - {file.name}")
        else:
            logger.info("âœ… æœªå‘ç°ä¸å®Œæ•´æ–‡ä»¶")
        
        return incomplete_files
    
    def clean_incomplete_files(self):
        """æ¸…ç†ä¸å®Œæ•´çš„æ–‡ä»¶"""
        logger.info("ğŸ§¹ æ¸…ç†ä¸å®Œæ•´çš„æ–‡ä»¶...")
        
        incomplete_files = self.check_incomplete_files()
        
        if not incomplete_files:
            logger.info("âœ… æ— éœ€æ¸…ç†")
            return True
        
        try:
            for file in incomplete_files:
                logger.info(f"åˆ é™¤: {file.name}")
                file.unlink()
            
            logger.info(f"âœ… å·²æ¸…ç† {len(incomplete_files)} ä¸ªä¸å®Œæ•´æ–‡ä»¶")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")
            return False
    
    def clean_entire_cache(self):
        """å®Œå…¨æ¸…ç†æ¨¡å‹ç¼“å­˜"""
        logger.info("ğŸ—‘ï¸  å®Œå…¨æ¸…ç†æ¨¡å‹ç¼“å­˜...")
        
        if self.model_cache_path.exists():
            try:
                shutil.rmtree(self.model_cache_path)
                logger.info("âœ… æ¨¡å‹ç¼“å­˜å·²å®Œå…¨æ¸…ç†")
                return True
            except Exception as e:
                logger.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")
                return False
        else:
            logger.info("âœ… ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")
            return True
    
    def download_model_with_retry(self, max_retries=3):
        """é‡æ–°ä¸‹è½½æ¨¡å‹"""
        logger.info(f"ğŸ“¥ å¼€å§‹é‡æ–°ä¸‹è½½æ¨¡å‹ (æœ€å¤šé‡è¯• {max_retries} æ¬¡)...")
        
        for attempt in range(1, max_retries + 1):
            try:
                logger.info(f"ğŸ”„ ç¬¬ {attempt}/{max_retries} æ¬¡å°è¯•...")
                
                # ä¸‹è½½æ¨¡å‹
                local_dir = snapshot_download(
                    repo_id=self.model_id,
                    cache_dir=str(self.cache_dir),
                    resume_download=True,
                    local_files_only=False,
                    force_download=False,
                    token=None
                )
                
                logger.info(f"âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ: {local_dir}")
                return True, local_dir
                
            except Exception as e:
                logger.error(f"âŒ ç¬¬ {attempt} æ¬¡ä¸‹è½½å¤±è´¥: {e}")
                if attempt < max_retries:
                    wait_time = 30 * attempt  # é€’å¢ç­‰å¾…æ—¶é—´
                    logger.info(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    logger.error("âŒ æ‰€æœ‰ä¸‹è½½å°è¯•éƒ½å¤±è´¥äº†")
        
        return False, None
    
    def verify_download(self):
        """éªŒè¯ä¸‹è½½å®Œæ•´æ€§"""
        logger.info("ğŸ” éªŒè¯ä¸‹è½½å®Œæ•´æ€§...")
        
        # æ£€æŸ¥å…³é”®ç›®å½•
        required_dirs = [
            "scheduler",
            "text_encoder",
            "text_encoder_2", 
            "text_encoder_3",
            "tokenizer",
            "tokenizer_2",
            "tokenizer_3",
            "transformer",
            "vae"
        ]
        
        snapshots_dir = self.model_cache_path / "snapshots"
        if not snapshots_dir.exists():
            logger.error("âŒ snapshotsç›®å½•ä¸å­˜åœ¨")
            return False
        
        # æ‰¾åˆ°æœ€æ–°çš„snapshot
        snapshot_dirs = [d for d in snapshots_dir.iterdir() if d.is_dir()]
        if not snapshot_dirs:
            logger.error("âŒ æœªæ‰¾åˆ°snapshotç›®å½•")
            return False
        
        latest_snapshot = snapshot_dirs[0]  # å‡è®¾åªæœ‰ä¸€ä¸ª
        logger.info(f"ğŸ“ æ£€æŸ¥snapshot: {latest_snapshot.name}")
        
        missing_dirs = []
        for req_dir in required_dirs:
            dir_path = latest_snapshot / req_dir
            if not dir_path.exists():
                missing_dirs.append(req_dir)
            else:
                # æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©º
                if not any(dir_path.iterdir()):
                    missing_dirs.append(f"{req_dir} (ç©ºç›®å½•)")
        
        if missing_dirs:
            logger.error(f"âŒ ç¼ºå°‘å…³é”®ç›®å½•: {missing_dirs}")
            return False
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸å®Œæ•´æ–‡ä»¶
        incomplete_files = self.check_incomplete_files()
        if incomplete_files:
            logger.error(f"âŒ ä»æœ‰ä¸å®Œæ•´æ–‡ä»¶: {len(incomplete_files)}")
            return False
        
        logger.info("âœ… ä¸‹è½½éªŒè¯é€šè¿‡")
        return True
    
    def run_clean_and_redownload(self, force_clean=False):
        """æ‰§è¡Œæ¸…ç†å’Œé‡æ–°ä¸‹è½½"""
        logger.info("="*60)
        logger.info("ğŸ”§ SD3.5æ¨¡å‹æ¸…ç†å’Œé‡æ–°ä¸‹è½½å·¥å…·")
        logger.info("="*60)
        
        if force_clean:
            logger.info("ğŸ—‘ï¸  å¼ºåˆ¶å®Œå…¨æ¸…ç†æ¨¡å¼")
            if not self.clean_entire_cache():
                return False
        else:
            logger.info("ğŸ§¹ æ™ºèƒ½æ¸…ç†æ¨¡å¼")
            if not self.clean_incomplete_files():
                return False
        
        # é‡æ–°ä¸‹è½½
        success, local_dir = self.download_model_with_retry()
        
        if success:
            # éªŒè¯ä¸‹è½½
            if self.verify_download():
                logger.info("ğŸ‰ æ¨¡å‹ä¸‹è½½å’ŒéªŒè¯å®Œæˆï¼")
                return True
            else:
                logger.error("âŒ ä¸‹è½½éªŒè¯å¤±è´¥")
                return False
        else:
            logger.error("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
            return False

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    cleaner = ModelCacheCleaner()
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    force_clean = "--force" in sys.argv
    
    if force_clean:
        print("âš ï¸  è­¦å‘Š: å°†å®Œå…¨åˆ é™¤ç°æœ‰æ¨¡å‹ç¼“å­˜")
        response = input("ç¡®è®¤ç»§ç»­? (y/N): ")
        if response.lower() != 'y':
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return
    
    success = cleaner.run_clean_and_redownload(force_clean=force_clean)
    
    if success:
        print("\n" + "="*60)
        print("âœ… SD3.5æ¨¡å‹å‡†å¤‡å°±ç»ªï¼")
        print("ğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("   python test_sd35_model.py  # æµ‹è¯•æ¨¡å‹")
        print("   python demo_environmental_generator.py  # å¼€å§‹ä½¿ç”¨")
        print("="*60)
    else:
        print("\n" + "="*60)
        print("âŒ æ¸…ç†å’Œä¸‹è½½å¤±è´¥")
        print("ğŸ”§ å»ºè®®:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   2. å°è¯•ä½¿ç”¨ --force å‚æ•°å®Œå…¨é‡æ–°ä¸‹è½½")
        print("   3. æ£€æŸ¥ç£ç›˜ç©ºé—´")
        print("="*60)

if __name__ == "__main__":
    main()