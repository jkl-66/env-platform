#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨å›½å†…é•œåƒç«™ç‚¹ä¸‹è½½SD3.5æ¨¡å‹
"""

import os
import shutil
import logging
from pathlib import Path
import requests
import time
from urllib.parse import urljoin
import json
import hashlib

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ChinaMirrorDownloader:
    def __init__(self):
        self.cache_dir = Path("./cache/huggingface")
        self.model_id = "stabilityai/stable-diffusion-3.5-large-turbo"
        self.model_cache_path = self.cache_dir / "models--stabilityai--stable-diffusion-3.5-large-turbo"
        
        # å›½å†…é•œåƒç«™ç‚¹åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        self.mirrors = [
            "https://hf-mirror.com",
            "https://huggingface.co",  # åŸç«™ä½œä¸ºå¤‡é€‰
        ]
        
        # å¿…éœ€çš„æ–‡ä»¶åˆ—è¡¨
        self.required_files = [
            "model_index.json",
            "scheduler/scheduler_config.json",
            "text_encoder/config.json",
            "text_encoder/model.safetensors",
            "text_encoder_2/config.json", 
            "text_encoder_2/model.safetensors",
            "text_encoder_3/config.json",
            "text_encoder_3/model.safetensors",
            "tokenizer/tokenizer_config.json",
            "tokenizer/tokenizer.json",
            "tokenizer_2/tokenizer_config.json",
            "tokenizer_2/tokenizer.json",
            "tokenizer_3/tokenizer_config.json",
            "tokenizer_3/tokenizer.json",
            "transformer/config.json",
            "transformer/diffusion_pytorch_model-00001-of-00002.safetensors",
            "transformer/diffusion_pytorch_model-00002-of-00002.safetensors",
            "transformer/diffusion_pytorch_model.safetensors.index.json",
            "vae/config.json",
            "vae/diffusion_pytorch_model.safetensors"
        ]
    
    def test_mirror_connection(self, mirror_url):
        """æµ‹è¯•é•œåƒç«™ç‚¹è¿æ¥"""
        try:
            # ä½¿ç”¨æ›´ç®€å•çš„æµ‹è¯•URL
            test_url = f"{mirror_url}/{self.model_id}/resolve/main/model_index.json"
            
            # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.head(test_url, timeout=15, headers=headers, allow_redirects=True)
            if response.status_code in [200, 302]:
                logger.info(f"âœ… é•œåƒå¯ç”¨: {mirror_url}")
                return True
            else:
                logger.warning(f"âŒ é•œåƒä¸å¯ç”¨: {mirror_url} (çŠ¶æ€ç : {response.status_code})")
                return False
        except Exception as e:
            logger.warning(f"âŒ é•œåƒè¿æ¥å¤±è´¥: {mirror_url} - {e}")
            return False
    
    def download_file(self, mirror_url, file_path, local_path, max_retries=3):
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        download_url = f"{mirror_url}/{self.model_id}/resolve/main/{file_path}"
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        for attempt in range(1, max_retries + 1):
            try:
                logger.info(f"ğŸ“¥ ä¸‹è½½ {file_path} (å°è¯• {attempt}/{max_retries})")
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                local_path.parent.mkdir(parents=True, exist_ok=True)
                
                # ä¸‹è½½æ–‡ä»¶
                response = requests.get(download_url, stream=True, timeout=60, headers=headers)
                response.raise_for_status()
                
                # è·å–æ–‡ä»¶å¤§å°
                total_size = int(response.headers.get('content-length', 0))
                
                # å†™å…¥æ–‡ä»¶
                downloaded_size = 0
                with open(local_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            
                            # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯10MBæ˜¾ç¤ºä¸€æ¬¡ï¼‰
                            if downloaded_size % (10 * 1024 * 1024) == 0 and total_size > 0:
                                progress = (downloaded_size / total_size) * 100
                                logger.info(f"   è¿›åº¦: {progress:.1f}% ({downloaded_size:,}/{total_size:,} bytes)")
                
                # éªŒè¯æ–‡ä»¶å¤§å°
                file_size = local_path.stat().st_size
                if file_size > 0:
                    logger.info(f"âœ… {file_path} ä¸‹è½½å®Œæˆ ({file_size:,} bytes)")
                    return True
                else:
                    logger.error(f"âŒ {file_path} æ–‡ä»¶ä¸ºç©º")
                    local_path.unlink(missing_ok=True)
                    
            except Exception as e:
                logger.error(f"âŒ {file_path} ä¸‹è½½å¤±è´¥ (å°è¯• {attempt}): {e}")
                local_path.unlink(missing_ok=True)
                
                if attempt < max_retries:
                    wait_time = 5 * attempt
                    logger.info(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
        
        return False
    
    def create_snapshot_structure(self):
        """åˆ›å»ºsnapshotç›®å½•ç»“æ„"""
        # ä½¿ç”¨å›ºå®šçš„commit hash
        commit_hash = "ec07796fc06b096cc56de9762974a28f4c632eda"
        
        snapshot_dir = self.model_cache_path / "snapshots" / commit_hash
        snapshot_dir.mkdir(parents=True, exist_ok=True)
        
        return snapshot_dir
    
    def download_model_from_mirror(self):
        """ä»é•œåƒç«™ç‚¹ä¸‹è½½æ¨¡å‹"""
        logger.info("ğŸ” æµ‹è¯•å›½å†…é•œåƒç«™ç‚¹è¿æ¥...")
        
        # æ‰¾åˆ°å¯ç”¨çš„é•œåƒ
        working_mirror = None
        for mirror in self.mirrors:
            logger.info(f"ğŸŒ æµ‹è¯•é•œåƒ: {mirror}")
            if self.test_mirror_connection(mirror):
                working_mirror = mirror
                break
            time.sleep(2)  # ç­‰å¾…2ç§’å†æµ‹è¯•ä¸‹ä¸€ä¸ªé•œåƒ
        
        if not working_mirror:
            logger.error("âŒ æ‰€æœ‰é•œåƒç«™ç‚¹éƒ½ä¸å¯ç”¨")
            logger.info("ğŸ’¡ å»ºè®®:")
            logger.info("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            logger.info("   2. å°è¯•ä½¿ç”¨VPN")
            logger.info("   3. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®")
            return False
        
        logger.info(f"ğŸŒ ä½¿ç”¨é•œåƒ: {working_mirror}")
        
        # æ¸…ç†ç°æœ‰ç¼“å­˜
        if self.model_cache_path.exists():
            logger.info("ğŸ—‘ï¸  æ¸…ç†ç°æœ‰ç¼“å­˜...")
            shutil.rmtree(self.model_cache_path)
        
        # åˆ›å»ºsnapshotç›®å½•
        snapshot_dir = self.create_snapshot_structure()
        logger.info(f"ğŸ“ åˆ›å»ºsnapshotç›®å½•: {snapshot_dir.name}")
        
        # ä¸‹è½½æ‰€æœ‰å¿…éœ€æ–‡ä»¶
        success_count = 0
        total_files = len(self.required_files)
        
        logger.info(f"ğŸ“¦ å¼€å§‹ä¸‹è½½ {total_files} ä¸ªæ–‡ä»¶...")
        
        for i, file_path in enumerate(self.required_files, 1):
            logger.info(f"\nğŸ“„ [{i}/{total_files}] {file_path}")
            local_path = snapshot_dir / file_path
            
            if self.download_file(working_mirror, file_path, local_path):
                success_count += 1
            else:
                logger.error(f"âŒ å…³é”®æ–‡ä»¶ä¸‹è½½å¤±è´¥: {file_path}")
                # ç»§ç»­ä¸‹è½½å…¶ä»–æ–‡ä»¶ï¼Œä¸è¦ç«‹å³é€€å‡º
        
        logger.info(f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡: {success_count}/{total_files} æ–‡ä»¶æˆåŠŸ")
        
        if success_count == total_files:
            logger.info("âœ… æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å®Œæˆ")
            return True
        elif success_count >= total_files * 0.8:  # 80%ä»¥ä¸Šæ–‡ä»¶ä¸‹è½½æˆåŠŸ
            logger.warning(f"âš ï¸  éƒ¨åˆ†æ–‡ä»¶ä¸‹è½½å®Œæˆï¼Œç¼ºå°‘ {total_files - success_count} ä¸ªæ–‡ä»¶")
            logger.info("ğŸ”„ å¯ä»¥å°è¯•é‡æ–°è¿è¡Œè„šæœ¬ä¸‹è½½ç¼ºå¤±æ–‡ä»¶")
            return True
        else:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥ï¼Œç¼ºå°‘ {total_files - success_count} ä¸ªæ–‡ä»¶")
            return False
    
    def verify_download(self):
        """éªŒè¯ä¸‹è½½å®Œæ•´æ€§"""
        logger.info("ğŸ” éªŒè¯ä¸‹è½½å®Œæ•´æ€§...")
        
        snapshots_dir = self.model_cache_path / "snapshots"
        if not snapshots_dir.exists():
            logger.error("âŒ snapshotsç›®å½•ä¸å­˜åœ¨")
            return False
        
        # æ‰¾åˆ°snapshotç›®å½•
        snapshot_dirs = [d for d in snapshots_dir.iterdir() if d.is_dir()]
        if not snapshot_dirs:
            logger.error("âŒ æœªæ‰¾åˆ°snapshotç›®å½•")
            return False
        
        snapshot_dir = snapshot_dirs[0]
        logger.info(f"ğŸ“ éªŒè¯snapshot: {snapshot_dir.name}")
        
        # æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶
        missing_files = []
        empty_files = []
        
        for file_path in self.required_files:
            full_path = snapshot_dir / file_path
            if not full_path.exists():
                missing_files.append(file_path)
            elif full_path.stat().st_size == 0:
                empty_files.append(file_path)
            else:
                # æ–‡ä»¶å­˜åœ¨ä¸”éç©º
                pass
        
        if missing_files:
            logger.error(f"âŒ ç¼ºå°‘æ–‡ä»¶ ({len(missing_files)}ä¸ª): {missing_files[:3]}...")  # åªæ˜¾ç¤ºå‰3ä¸ª
        
        if empty_files:
            logger.error(f"âŒ ç©ºæ–‡ä»¶ ({len(empty_files)}ä¸ª): {empty_files[:3]}...")  # åªæ˜¾ç¤ºå‰3ä¸ª
        
        if missing_files or empty_files:
            return False
        
        logger.info("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶éªŒè¯é€šè¿‡")
        return True
    
    def run_china_mirror_download(self):
        """æ‰§è¡Œå›½å†…é•œåƒä¸‹è½½"""
        logger.info("="*60)
        logger.info("ğŸ‡¨ğŸ‡³ SD3.5æ¨¡å‹å›½å†…é•œåƒä¸‹è½½å·¥å…·")
        logger.info("="*60)
        
        # ä¸‹è½½æ¨¡å‹
        if self.download_model_from_mirror():
            # éªŒè¯ä¸‹è½½
            if self.verify_download():
                logger.info("ğŸ‰ æ¨¡å‹ä¸‹è½½å’ŒéªŒè¯å®Œæˆï¼")
                return True
            else:
                logger.warning("âš ï¸  ä¸‹è½½éªŒè¯éƒ¨åˆ†å¤±è´¥ï¼Œä½†å¯ä»¥å°è¯•ä½¿ç”¨")
                return True  # å³ä½¿éªŒè¯å¤±è´¥ä¹Ÿè¿”å›Trueï¼Œè®©ç”¨æˆ·å°è¯•ä½¿ç”¨
        else:
            logger.error("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
            return False

def main():
    """ä¸»å‡½æ•°"""
    downloader = ChinaMirrorDownloader()
    
    success = downloader.run_china_mirror_download()
    
    if success:
        print("\n" + "="*60)
        print("âœ… SD3.5æ¨¡å‹å‡†å¤‡å°±ç»ªï¼")
        print("ğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("   python test_sd35_model.py  # æµ‹è¯•æ¨¡å‹")
        print("   python demo_environmental_generator.py  # å¼€å§‹ä½¿ç”¨")
        print("="*60)
    else:
        print("\n" + "="*60)
        print("âŒ å›½å†…é•œåƒä¸‹è½½å¤±è´¥")
        print("ğŸ”§ å»ºè®®:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   2. å°è¯•ä½¿ç”¨VPN")
        print("   3. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®")
        print("   4. ç¨åé‡è¯•")
        print("   5. è”ç³»ç½‘ç»œç®¡ç†å‘˜")
        print("="*60)

if __name__ == "__main__":
    main()