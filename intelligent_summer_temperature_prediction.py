#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½å¤å­£æœ€é«˜æ°”æ¸©é¢„æµ‹ç³»ç»Ÿ - æ·±åº¦å­¦ä¹ ç‰ˆæœ¬
ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œé¢„æµ‹ä¸Šæµ·åœ°åŒºï¼ˆä¸œç»120Â°52â€²è‡³122Â°12â€²ï¼ŒåŒ—çº¬30Â°40â€²è‡³31Â°53â€²ï¼‰å¤å­£æœ€é«˜æ°”æ¸©
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·±åº¦å­¦ä¹ ç›¸å…³åº“
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import TensorDataset, DataLoader
    import torch.nn.functional as F
    import xgboost as xgb
    from sqlalchemy import create_engine
    import json

    # GPUé…ç½®
    print("ğŸ”§ é…ç½®GPUåŠ é€Ÿ...")
    if torch.cuda.is_available():
        device = torch.device('cuda')
        gpu_count = torch.cuda.device_count()
        gpu_names = [torch.cuda.get_device_name(i) for i in range(gpu_count)]
        print(f"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUè®¾å¤‡ï¼Œå·²å¯ç”¨GPUåŠ é€Ÿ")
        print(f"ğŸ“± GPUè®¾å¤‡: {gpu_names}")
        print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")
    else:
        device = torch.device('cpu')
        print("âš ï¸ æœªæ£€æµ‹åˆ°GPUè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")

    print("âœ… PyTorch å·²åŠ è½½")
except ImportError:
    print("âš ï¸ æ­£åœ¨å®‰è£… PyTorch...")
    import subprocess
    subprocess.check_call(["pip", "install", "torch", "torchvision", "torchaudio"])
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    import torch.nn.functional as F
    
    # GPUé…ç½®
    print("ğŸ”§ é…ç½®GPUåŠ é€Ÿ...")
    if torch.cuda.is_available():
        device = torch.device('cuda')
        gpu_count = torch.cuda.device_count()
        gpu_names = [torch.cuda.get_device_name(i) for i in range(gpu_count)]
        print(f"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUè®¾å¤‡ï¼Œå·²å¯ç”¨GPUåŠ é€Ÿ")
        print(f"ğŸ“± GPUè®¾å¤‡: {gpu_names}")
        print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")
    else:
        device = torch.device('cpu')
        print("âš ï¸ æœªæ£€æµ‹åˆ°GPUè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")

# ç§‘å­¦è®¡ç®—åº“
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from scipy import stats
from scipy.signal import savgol_filter
import math

# æ•°æ®å¤„ç†åº“
try:
    import xarray as xr
    print("âœ… xarray å·²åŠ è½½")
except ImportError:
    print("âš ï¸ æ­£åœ¨å®‰è£… xarray...")
    import subprocess
    subprocess.check_call(["pip", "install", "xarray"])
    import xarray as xr

try:
    import cfgrib
    print("âœ… cfgrib å·²åŠ è½½")
except ImportError:
    print("âš ï¸ æ­£åœ¨å®‰è£… cfgrib...")
    import subprocess
    subprocess.check_call(["pip", "install", "cfgrib"])
    import cfgrib

# ä¸­æ–‡å­—ä½“è®¾ç½®
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class IntelligentTemperaturePrediction:
    """
    æ™ºèƒ½å¤å­£æœ€é«˜æ°”æ¸©é¢„æµ‹ç³»ç»Ÿ
    ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹é¢„æµ‹ä¸Šæµ·åœ°åŒºå¤å­£æœ€é«˜æ°”æ¸©
    """
    
    def __init__(self, grib_file_path=None, db_config_path='mysql_config.json'):
        self.grib_file_path = grib_file_path
        self.data = None
        self.processed_data = None
        self.models = {}
        self.scalers = {}
        self.results = {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ä¸Šæµ·åœ°åŒºåœ°ç†èŒƒå›´
        self.lon_range = (120.87, 122.2)  # ä¸œç»120Â°52â€²è‡³122Â°12â€²
        self.lat_range = (30.67, 31.88)   # åŒ—çº¬30Â°40â€²è‡³31Â°53â€²
        
        # ä¸Šæµ·åœ°åŒºå¤å­£æ°”æ¸©ç‰¹å¾ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
        self.shanghai_climate = {
            'summer_avg_high': 32.0,  # å¤å­£å¹³å‡æœ€é«˜æ°”æ¸©
            'summer_max_record': 40.9,  # å†å²æœ€é«˜æ°”æ¸©è®°å½•
            'summer_min_high': 28.0,   # å¤å­£æœ€ä½çš„æœ€é«˜æ°”æ¸©
            'peak_months': [7, 8],     # æœ€çƒ­æœˆä»½
            'heat_wave_threshold': 35.0  # é«˜æ¸©é¢„è­¦é˜ˆå€¼
        }
        
        print("ğŸŒ¡ï¸ æ™ºèƒ½å¤å­£æœ€é«˜æ°”æ¸©é¢„æµ‹ç³»ç»Ÿå·²åˆå§‹åŒ–")
        print(f"ğŸ“ ç›®æ ‡åŒºåŸŸ: ä¸Šæµ·åœ°åŒº (ä¸œç»{self.lon_range[0]:.2f}Â°-{self.lon_range[1]:.2f}Â°, åŒ—çº¬{self.lat_range[0]:.2f}Â°-{self.lat_range[1]:.2f}Â°)")

    def load_data_from_db(self):
        """
        ä»MySQLæ•°æ®åº“åŠ è½½æ°”å€™æ•°æ®
        """
        try:
            with open(self.db_config_path, 'r') as f:
                config = json.load(f)['mysql']
            
            engine = create_engine(f"mysql+pymysql://{config['user']}:{config['password']}@{config['host']}:{config['port']}/jkl")
            
            query = """
            SELECT * FROM climate_metadata 
            WHERE latitude BETWEEN 30.67 AND 31.88 
            AND longitude BETWEEN 120.87 AND 122.2
            """
            
            self.data = pd.read_sql(query, engine)
            
            if self.data.empty:
                print("æ•°æ®åº“ä¸­æœªæ‰¾åˆ°æŒ‡å®šèŒƒå›´å†…çš„æ•°æ®ï¼Œå°†ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ã€‚")
                return self._generate_shanghai_simulated_data()

            self.data['time'] = pd.to_datetime(self.data['time'])
            self.data = self.data.set_index('time')
            self.data = self.data.rename(columns={'temperature': 't2m'})
            self.processed_data = self.data.copy()

            print(f"âœ… ä»æ•°æ®åº“æˆåŠŸåŠ è½½ {len(self.data)} æ¡æ•°æ®")
            return True
        except Exception as e:
            print(f"âŒ ä»æ•°æ®åº“åŠ è½½æ•°æ®å¤±è´¥: {e}")
            print("ğŸ”„ å°†ç”Ÿæˆä¸Šæµ·åœ°åŒºæ¨¡æ‹Ÿæ•°æ®...")
            return self._generate_shanghai_simulated_data()

    def load_grib_data(self):
        """
        åŠ è½½GRIBæ•°æ®å¹¶æå–ä¸Šæµ·åœ°åŒºæ•°æ®
        """
        if not self.grib_file_path:
            print("âš ï¸ æœªæä¾›GRIBæ–‡ä»¶è·¯å¾„ï¼Œå°†ç”Ÿæˆä¸Šæµ·åœ°åŒºæ¨¡æ‹Ÿæ•°æ®")
            return self._generate_shanghai_simulated_data()
        
        try:
            print(f"ğŸ“‚ æ­£åœ¨åŠ è½½GRIBæ•°æ®: {self.grib_file_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            import os
            if not os.path.exists(self.grib_file_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {self.grib_file_path}")
                print("ğŸ”„ å°†ç”Ÿæˆä¸Šæµ·åœ°åŒºæ¨¡æ‹Ÿæ•°æ®...")
                return self._generate_shanghai_simulated_data()
            
            # ä½¿ç”¨xarrayå’Œcfgribè¯»å–GRIBæ•°æ®
            self.data = xr.open_dataset(self.grib_file_path, engine='cfgrib')
            
            # æŸ¥æ‰¾æ¸©åº¦ç›¸å…³å˜é‡
            temp_vars = [var for var in self.data.data_vars if any(keyword in var.lower() 
                        for keyword in ['temp', 't2m', 'temperature', '2t'])]
            
            if not temp_vars:
                print("âš ï¸ æœªæ‰¾åˆ°æ¸©åº¦å˜é‡ï¼ŒæŸ¥çœ‹æ‰€æœ‰å˜é‡:")
                print(list(self.data.data_vars.keys()))
                if self.data.data_vars:
                    temp_var = list(self.data.data_vars.keys())[0]
                    print(f"ğŸ“Š ä½¿ç”¨å˜é‡: {temp_var}")
                else:
                    raise ValueError("GRIBæ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½•æ•°æ®å˜é‡")
            else:
                temp_var = temp_vars[0]
                print(f"ğŸŒ¡ï¸ æ‰¾åˆ°æ¸©åº¦å˜é‡: {temp_var}")
            
            # é‡å‘½åæ¸©åº¦å˜é‡ä¸ºæ ‡å‡†åç§°
            if temp_var != 't2m':
                self.data = self.data.rename({temp_var: 't2m'})
            
            # è½¬æ¢ä¸ºæ‘„æ°åº¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.data['t2m'].attrs.get('units') == 'K':
                self.data['t2m'] = self.data['t2m'] - 273.15
                self.data['t2m'].attrs['units'] = 'C'
            
            # æå–ä¸Šæµ·åœ°åŒºæ•°æ®
            self.data = self.data.sel(
                longitude=slice(self.lon_range[0], self.lon_range[1]),
                latitude=slice(self.lat_range[0], self.lat_range[1])
            )
            
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
            print(f"ğŸ“Š æ•°æ®ç»´åº¦: {self.data.dims}")
            print(f"ğŸ—“ï¸ æ—¶é—´èŒƒå›´: {self.data.time.min().values} åˆ° {self.data.time.max().values}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è¯»å–GRIBæ–‡ä»¶å¤±è´¥: {e}")
            print("ğŸ”„ å°†ç”Ÿæˆä¸Šæµ·åœ°åŒºæ¨¡æ‹Ÿæ•°æ®...")
            return self._generate_shanghai_simulated_data()
    
    def _generate_shanghai_simulated_data(self):
        """
        ç”Ÿæˆç¬¦åˆä¸Šæµ·åœ°åŒºæ°”å€™ç‰¹å¾çš„æ¨¡æ‹Ÿæ•°æ®
        """
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆä¸Šæµ·åœ°åŒºå¤å­£æ°”æ¸©æ¨¡æ‹Ÿæ•°æ®...")
        
        # ç”Ÿæˆ1980-2024å¹´çš„æ•°æ®
        start_year = 1980
        end_year = 2024
        years = list(range(start_year, end_year + 1))
        
        # åˆ›å»ºæ—¶é—´åºåˆ—
        dates = []
        temperatures = []
        
        for year in years:
            # å¤å­£æœˆä»½ï¼š6, 7, 8æœˆ
            for month in [6, 7, 8]:
                days_in_month = 30 if month in [6, 8] else 31
                for day in range(1, days_in_month + 1):
                    try:
                        date = datetime(year, month, day)
                        dates.append(date)
                        
                        # ç”Ÿæˆç¬¦åˆä¸Šæµ·æ°”å€™çš„æ¸©åº¦æ•°æ®
                        temp = self._generate_realistic_shanghai_temperature(year, month, day)
                        temperatures.append(temp)
                    except ValueError:
                        continue
        
        # åˆ›å»ºDataFrame
        self.processed_data = pd.DataFrame({
            'date': dates,
            'temperature': temperatures,
            'year': [d.year for d in dates],
            'month': [d.month for d in dates],
            'day': [d.day for d in dates],
            'day_of_year': [d.timetuple().tm_yday for d in dates]
        })
        
        print(f"âœ… ç”Ÿæˆäº† {len(self.processed_data)} ä¸ªæ•°æ®ç‚¹")
        print(f"ğŸŒ¡ï¸ æ¸©åº¦èŒƒå›´: {self.processed_data['temperature'].min():.1f}Â°C - {self.processed_data['temperature'].max():.1f}Â°C")
        print(f"ğŸ“Š å¹³å‡æ¸©åº¦: {self.processed_data['temperature'].mean():.1f}Â°C")
        
        return True
    
    def _generate_realistic_shanghai_temperature(self, year, month, day):
        """
        ç”Ÿæˆç¬¦åˆä¸Šæµ·åœ°åŒºå®é™…æ°”å€™çš„æ¸©åº¦æ•°æ®
        """
        # åŸºç¡€æ¸©åº¦ï¼ˆæ ¹æ®æœˆä»½ï¼‰
        base_temps = {6: 29.0, 7: 33.0, 8: 32.5}
        base_temp = base_temps[month]
        
        # å¹´é™…å˜åŒ–è¶‹åŠ¿ï¼ˆå…¨çƒå˜æš–å½±å“ï¼‰
        warming_trend = (year - 1980) * 0.02  # æ¯å¹´å‡æ¸©0.02Â°C
        
        # æœˆå†…å˜åŒ–ï¼ˆä¸­æ—¬æœ€çƒ­ï¼‰
        if day <= 10:
            month_factor = 0.8 + (day / 10) * 0.2
        elif day <= 20:
            month_factor = 1.0
        else:
            month_factor = 1.0 - ((day - 20) / 10) * 0.15
        
        # éšæœºæ³¢åŠ¨
        daily_variation = np.random.normal(0, 2.5)
        
        # æç«¯å¤©æ°”äº‹ä»¶ï¼ˆçƒ­æµªï¼‰
        heat_wave_prob = 0.05 if month == 7 else 0.02
        if np.random.random() < heat_wave_prob:
            heat_wave_boost = np.random.uniform(3, 8)
        else:
            heat_wave_boost = 0
        
        # è®¡ç®—æœ€ç»ˆæ¸©åº¦
        temperature = base_temp + warming_trend + (base_temp * (month_factor - 1)) + daily_variation + heat_wave_boost
        
        # ç¡®ä¿æ¸©åº¦åœ¨åˆç†èŒƒå›´å†…
        temperature = np.clip(temperature, 22.0, 42.0)
        
        return temperature
    
    def create_features(self):
        """
        åˆ›å»ºæ¨¡å‹çš„ç‰¹å¾
        """
        print("ğŸ”§ æ­£åœ¨åˆ›å»ºæ·±åº¦å­¦ä¹ ç‰¹å¾...")
        
        df = self.processed_data.copy()
        
        # æ—¶é—´ç‰¹å¾
        df['sin_day'] = np.sin(2 * np.pi * df['day_of_year'] / 365)
        df['cos_day'] = np.cos(2 * np.pi * df['day_of_year'] / 365)
        df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)
        df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)
        
        # æ»åç‰¹å¾
        for lag in [1, 2, 3, 5, 7, 14]:
            df[f'temp_lag_{lag}'] = df['temperature'].shift(lag)
        
        # æ»‘åŠ¨çª—å£ç»Ÿè®¡ç‰¹å¾
        for window in [3, 7, 14, 30]:
            df[f'temp_mean_{window}'] = df['temperature'].rolling(window=window).mean()
            df[f'temp_std_{window}'] = df['temperature'].rolling(window=window).std()
            df[f'temp_max_{window}'] = df['temperature'].rolling(window=window).max()
            df[f'temp_min_{window}'] = df['temperature'].rolling(window=window).min()
        
        # å¹´é™…è¶‹åŠ¿
        df['year_normalized'] = (df['year'] - df['year'].min()) / (df['year'].max() - df['year'].min())
        
        # çƒ­æµªæŒ‡æ ‡
        df['is_heat_wave'] = (df['temperature'] > self.shanghai_climate['heat_wave_threshold']).astype(int)
        df['heat_wave_duration'] = df.groupby((df['is_heat_wave'] != df['is_heat_wave'].shift()).cumsum())['is_heat_wave'].cumsum()
        
        # åˆ é™¤åŒ…å«NaNçš„è¡Œ
        df = df.dropna()
        
        self.processed_data = df
        print(f"âœ… ç‰¹å¾åˆ›å»ºå®Œæˆï¼Œå…± {len(df)} ä¸ªæ ·æœ¬ï¼Œ{len(df.columns)} ä¸ªç‰¹å¾")
        
        return df
    
class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

    def build_models(self, input_dim, model_type='xgboost'):
        """
        æ„å»ºæ¨¡å‹
        """
        if model_type == 'xgboost':
            model = xgb.XGBRegressor(objective='reg:squarederror',
                                     n_estimators=1000,
                                     learning_rate=0.05,
                                     max_depth=5,
                                     min_child_weight=1,
                                     gamma=0.1,
                                     subsample=0.8,
                                     colsample_bytree=0.8,
                                     reg_alpha=0.005,
                                     random_state=42,
                                     n_jobs=-1)
        elif model_type == 'transformer':
            class TransformerModel(nn.Module):
                def __init__(self, input_dim, model_dim=128, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):
                    super(TransformerModel, self).__init__()
                    self.model_type = 'Transformer'
                    self.src_mask = None
                    self.pos_encoder = PositionalEncoding(model_dim, dropout)
                    self.transformer = nn.Transformer(model_dim, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)
                    self.encoder = nn.Linear(input_dim, model_dim)
                    self.decoder = nn.Linear(model_dim, 1)

                def forward(self, src):
                    src = self.encoder(src)
                    src = self.pos_encoder(src)
                    output = self.transformer(src, src)
                    output = self.decoder(output)
                    return output
            model = TransformerModel(input_dim)
            model = model.to(self.device)
        else:
            raise ValueError(f"Unsupported model type: {model_type}")
        
        return model
        
        return model
    
    def train_models(self):
        """
        è®­ç»ƒå¤šä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹
        """
        print("ğŸš€ å¼€å§‹è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹...")
        
        # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
        feature_cols = [col for col in self.processed_data.columns 
                       if col not in ['date', 'temperature']]
        
        X = self.processed_data[feature_cols].values
        y = self.processed_data['temperature'].values
        
        # æ•°æ®æ ‡å‡†åŒ–
        self.scalers['X'] = StandardScaler()
        self.scalers['y'] = StandardScaler()
        
        X_scaled = self.scalers['X'].fit_transform(X)
        y_scaled = self.scalers['y'].fit_transform(y.reshape(-1, 1)).ravel()
        
        # æ—¶é—´åºåˆ—åˆ†å‰²
        tscv = TimeSeriesSplit(n_splits=5)
        
        model_configs = {
            'xgboost': {'type': 'xgboost'},
            'transformer': {'type': 'transformer', 'epochs': 100}
        }
        
        for model_name, config in model_configs.items():
            print(f"\nğŸ”„ è®­ç»ƒ {model_name} æ¨¡å‹...")
            
            fold_scores = []
            
            for fold, (train_idx, val_idx) in enumerate(tscv.split(X_scaled)):
                print(f"  ğŸ“Š è®­ç»ƒæŠ˜ {fold + 1}/5...")
                
                X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]
                y_train, y_val = y_scaled[train_idx], y_scaled[val_idx]
                
                input_dim = X_train.shape[1]
                
                # æ„å»ºæ¨¡å‹
                model = self.build_models(input_dim, config['type'])
                
                # è½¬æ¢ä¸ºPyTorchå¼ é‡
                X_train_tensor = torch.FloatTensor(X_train).to(self.device)
                y_train_tensor = torch.FloatTensor(y_train).to(self.device)
                X_val_tensor = torch.FloatTensor(X_val).to(self.device)
                y_val_tensor = torch.FloatTensor(y_val).to(self.device)
                
                # åˆ›å»ºæ•°æ®åŠ è½½å™¨
                train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
                train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
                
                # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
                criterion = nn.MSELoss()
                optimizer = optim.Adam(model.parameters(), lr=0.001)
                scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5, min_lr=1e-6)
                
                # è®­ç»ƒæ¨¡å‹
                best_val_loss = float('inf')
                patience_counter = 0
                patience = 20
                
                for epoch in range(config['epochs']):
                    model.train()
                    train_loss = 0.0
                    
                    for batch_X, batch_y in train_loader:
                        optimizer.zero_grad()
                        outputs = model(batch_X).squeeze()
                        loss = criterion(outputs, batch_y)
                        loss.backward()
                        optimizer.step()
                        train_loss += loss.item()
                    
                    # éªŒè¯
                    model.eval()
                    with torch.no_grad():
                        val_outputs = model(X_val_tensor).squeeze()
                        val_loss = criterion(val_outputs, y_val_tensor).item()
                    
                    scheduler.step(val_loss)
                    
                    # æ—©åœ
                    if val_loss < best_val_loss:
                        best_val_loss = val_loss
                        patience_counter = 0
                        best_model_state = model.state_dict().copy()
                    else:
                        patience_counter += 1
                        if patience_counter >= patience:
                            break
                
                # æ¢å¤æœ€ä½³æ¨¡å‹
                model.load_state_dict(best_model_state)
                
                # è¯„ä¼°
                model.eval()
                with torch.no_grad():
                    val_pred = model(X_val_tensor).squeeze().cpu().numpy()
                    val_score = mean_absolute_error(y_val, val_pred)
                    fold_scores.append(val_score)
            
            avg_score = np.mean(fold_scores)
            print(f"  âœ… {model_name} å¹³å‡MAE: {avg_score:.4f}")
            
            X_final = X_scaled
            input_dim = X_final.shape[1]
            
            final_model = self.build_models(input_dim, config['type'])
            
            # è½¬æ¢ä¸ºPyTorchå¼ é‡
            X_final_tensor = torch.FloatTensor(X_final).to(self.device)
            y_final_tensor = torch.FloatTensor(y_scaled).to(self.device)
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            final_dataset = TensorDataset(X_final_tensor, y_final_tensor)
            final_loader = DataLoader(final_dataset, batch_size=32, shuffle=True)
            
            # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
            criterion = nn.MSELoss()
            optimizer = optim.Adam(final_model.parameters(), lr=0.001)
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=15, factor=0.5, min_lr=1e-6)
            
            # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
            best_loss = float('inf')
            patience_counter = 0
            patience = 30
            
            for epoch in range(config['epochs']):
                final_model.train()
                epoch_loss = 0.0
                
                for batch_X, batch_y in final_loader:
                    optimizer.zero_grad()
                    outputs = final_model(batch_X).squeeze()
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    optimizer.step()
                    epoch_loss += loss.item()
                
                avg_epoch_loss = epoch_loss / len(final_loader)
                scheduler.step(avg_epoch_loss)
                
                # æ—©åœ
                if avg_epoch_loss < best_loss:
                    best_loss = avg_epoch_loss
                    patience_counter = 0
                    best_final_state = final_model.state_dict().copy()
                else:
                    patience_counter += 1
                    if patience_counter >= patience:
                        break
            
            # æ¢å¤æœ€ä½³æ¨¡å‹
            final_model.load_state_dict(best_final_state)
            
            self.models[model_name] = {
                'model': final_model,
                'score': avg_score,
                'type': config['type']
            }
        
        print("\nâœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    
    def predict_future_temperatures(self, years_ahead=5):
        """
        é¢„æµ‹æœªæ¥å‡ å¹´çš„å¤å­£æœ€é«˜æ°”æ¸©
        """
        print(f"ğŸ”® é¢„æµ‹æœªæ¥ {years_ahead} å¹´çš„å¤å­£æœ€é«˜æ°”æ¸©...")
        
        current_year = self.processed_data['year'].max()
        future_years = list(range(current_year + 1, current_year + years_ahead + 1))
        
        predictions = {}
        
        for model_name, model_info in self.models.items():
            print(f"  ğŸ“Š ä½¿ç”¨ {model_name} æ¨¡å‹é¢„æµ‹...")
            
            model = model_info['model']
            model_type = model_info['type']
            
            year_predictions = []
            
            for year in future_years:
                # ä¸ºæ¯å¹´ç”Ÿæˆå¤å­£æ—¥æœŸ
                summer_dates = []
                for month in [6, 7, 8]:
                    days_in_month = 30 if month in [6, 8] else 31
                    for day in range(1, days_in_month + 1):
                        try:
                            date = datetime(year, month, day)
                            summer_dates.append(date)
                        except ValueError:
                            continue
                
                # åˆ›å»ºç‰¹å¾
                future_features = []
                for date in summer_dates:
                    features = self._create_future_features(date, year)
                    future_features.append(features)
                
                future_features = np.array(future_features)
                
                # æ ‡å‡†åŒ–ç‰¹å¾
                future_features_scaled = self.scalers['X'].transform(future_features)
                
                # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´æ•°æ®å½¢çŠ¶
                if model_type in ['lstm', 'gru']:
                    future_features_scaled = future_features_scaled.reshape(
                        future_features_scaled.shape[0], future_features_scaled.shape[1], 1
                    )
                
                # é¢„æµ‹
                model.eval()
                with torch.no_grad():
                    future_tensor = torch.FloatTensor(future_features_scaled).to(self.device)
                    pred_scaled = model(future_tensor).squeeze().cpu().numpy()
                pred_temp = self.scalers['y'].inverse_transform(pred_scaled.reshape(-1, 1)).ravel()
                
                # æ‰¾åˆ°æœ€é«˜æ¸©åº¦å’Œå¯¹åº”æ—¥æœŸ
                max_temp_idx = np.argmax(pred_temp)
                max_temp = pred_temp[max_temp_idx]
                max_temp_date = summer_dates[max_temp_idx]
                
                year_predictions.append({
                    'year': year,
                    'max_temperature': max_temp,
                    'max_temp_date': max_temp_date,
                    'avg_summer_temp': np.mean(pred_temp)
                })
            
            predictions[model_name] = year_predictions
        
        self.results['future_predictions'] = predictions
        return predictions
    
    def _create_future_features(self, date, year):
        """
        ä¸ºæœªæ¥æ—¥æœŸåˆ›å»ºç‰¹å¾
        """
        month = date.month
        day = date.day
        day_of_year = date.timetuple().tm_yday
        
        # åŸºç¡€ç‰¹å¾
        features = {
            'year': year,
            'month': month,
            'day': day,
            'day_of_year': day_of_year,
            'sin_day': np.sin(2 * np.pi * day_of_year / 365),
            'cos_day': np.cos(2 * np.pi * day_of_year / 365),
            'sin_month': np.sin(2 * np.pi * month / 12),
            'cos_month': np.cos(2 * np.pi * month / 12),
            'year_normalized': (year - self.processed_data['year'].min()) / (self.processed_data['year'].max() - self.processed_data['year'].min())
        }
        
        # æ»åç‰¹å¾ï¼ˆä½¿ç”¨å†å²å¹³å‡å€¼ï¼‰
        historical_avg = self.processed_data[
            (self.processed_data['month'] == month) & 
            (self.processed_data['day'] == day)
        ]['temperature'].mean()
        
        for lag in [1, 2, 3, 5, 7, 14]:
            features[f'temp_lag_{lag}'] = historical_avg
        
        # æ»‘åŠ¨çª—å£ç‰¹å¾ï¼ˆä½¿ç”¨å†å²å¹³å‡å€¼ï¼‰
        for window in [3, 7, 14, 30]:
            features[f'temp_mean_{window}'] = historical_avg
            features[f'temp_std_{window}'] = 2.0  # å‡è®¾æ ‡å‡†å·®
            features[f'temp_max_{window}'] = historical_avg + 3
            features[f'temp_min_{window}'] = historical_avg - 3
        
        # çƒ­æµªç‰¹å¾
        features['is_heat_wave'] = 0
        features['heat_wave_duration'] = 0
        
        # ç¡®ä¿ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
        feature_cols = [col for col in self.processed_data.columns 
                       if col not in ['date', 'temperature']]
        
        return [features.get(col, 0) for col in feature_cols]
    
    def create_visualizations(self):
        """
        åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        """
        print("ğŸ“Š æ­£åœ¨åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        import os
        output_dir = "outputs"
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. å†å²æ•°æ®åˆ†æå›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ä¸Šæµ·åœ°åŒºå¤å­£æœ€é«˜æ°”æ¸©æ™ºèƒ½åˆ†æ', fontsize=16, fontweight='bold')
        
        # å¹´é™…å˜åŒ–è¶‹åŠ¿
        yearly_max = self.processed_data.groupby('year')['temperature'].max()
        axes[0, 0].plot(yearly_max.index, yearly_max.values, 'b-', linewidth=2, alpha=0.7)
        axes[0, 0].plot(yearly_max.index, savgol_filter(yearly_max.values, 5, 2), 'r-', linewidth=3)
        axes[0, 0].set_title('å¹´åº¦æœ€é«˜æ°”æ¸©å˜åŒ–è¶‹åŠ¿', fontweight='bold')
        axes[0, 0].set_xlabel('å¹´ä»½')
        axes[0, 0].set_ylabel('æ¸©åº¦ (Â°C)')
        axes[0, 0].grid(True, alpha=0.3)
        
        # æœˆåº¦åˆ†å¸ƒ
        monthly_stats = self.processed_data.groupby('month')['temperature'].agg(['mean', 'max', 'min'])
        axes[0, 1].plot(monthly_stats.index, monthly_stats['mean'], 'g-', linewidth=3, label='å¹³å‡')
        axes[0, 1].plot(monthly_stats.index, monthly_stats['max'], 'r-', linewidth=2, label='æœ€é«˜')
        axes[0, 1].plot(monthly_stats.index, monthly_stats['min'], 'b-', linewidth=2, label='æœ€ä½')
        axes[0, 1].set_title('å¤å­£å„æœˆæ¸©åº¦åˆ†å¸ƒ', fontweight='bold')
        axes[0, 1].set_xlabel('æœˆä»½')
        axes[0, 1].set_ylabel('æ¸©åº¦ (Â°C)')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ¸©åº¦åˆ†å¸ƒç›´æ–¹å›¾
        axes[1, 0].hist(self.processed_data['temperature'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        axes[1, 0].axvline(self.shanghai_climate['heat_wave_threshold'], color='red', linestyle='--', linewidth=2, label='é«˜æ¸©é¢„è­¦çº¿')
        axes[1, 0].set_title('æ¸©åº¦åˆ†å¸ƒç›´æ–¹å›¾', fontweight='bold')
        axes[1, 0].set_xlabel('æ¸©åº¦ (Â°C)')
        axes[1, 0].set_ylabel('é¢‘æ¬¡')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        model_names = list(self.models.keys())
        model_scores = [self.models[name]['score'] for name in model_names]
        bars = axes[1, 1].bar(model_names, model_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        axes[1, 1].set_title('æ·±åº¦å­¦ä¹ æ¨¡å‹æ€§èƒ½å¯¹æ¯” (MAE)', fontweight='bold')
        axes[1, 1].set_ylabel('å¹³å‡ç»å¯¹è¯¯å·®')
        axes[1, 1].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars, model_scores):
            axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                           f'{score:.4f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(f'{output_dir}/intelligent_temperature_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. æœªæ¥é¢„æµ‹å›¾
        if 'future_predictions' in self.results:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('ä¸Šæµ·åœ°åŒºå¤å­£æœ€é«˜æ°”æ¸©æ™ºèƒ½é¢„æµ‹', fontsize=16, fontweight='bold')
            
            colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
            
            for i, (model_name, predictions) in enumerate(self.results['future_predictions'].items()):
                years = [p['year'] for p in predictions]
                max_temps = [p['max_temperature'] for p in predictions]
                avg_temps = [p['avg_summer_temp'] for p in predictions]
                
                # æœ€é«˜æ¸©åº¦é¢„æµ‹
                axes[0, 0].plot(years, max_temps, 'o-', color=colors[i], linewidth=2, 
                              markersize=8, label=f'{model_name}')
                
                # å¹³å‡æ¸©åº¦é¢„æµ‹
                axes[0, 1].plot(years, avg_temps, 's-', color=colors[i], linewidth=2, 
                              markersize=8, label=f'{model_name}')
            
            axes[0, 0].set_title('æœªæ¥å¹´åº¦æœ€é«˜æ°”æ¸©é¢„æµ‹', fontweight='bold')
            axes[0, 0].set_xlabel('å¹´ä»½')
            axes[0, 0].set_ylabel('æœ€é«˜æ¸©åº¦ (Â°C)')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].axhline(self.shanghai_climate['heat_wave_threshold'], color='red', 
                              linestyle='--', alpha=0.7, label='é«˜æ¸©é¢„è­¦çº¿')
            
            axes[0, 1].set_title('æœªæ¥å¤å­£å¹³å‡æ°”æ¸©é¢„æµ‹', fontweight='bold')
            axes[0, 1].set_xlabel('å¹´ä»½')
            axes[0, 1].set_ylabel('å¹³å‡æ¸©åº¦ (Â°C)')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
            
            # é¢„æµ‹æ—¥æœŸåˆ†å¸ƒ
            best_model = min(self.models.keys(), key=lambda x: self.models[x]['score'])
            best_predictions = self.results['future_predictions'][best_model]
            
            months = [p['max_temp_date'].month for p in best_predictions]
            days = [p['max_temp_date'].day for p in best_predictions]
            
            axes[1, 0].scatter(months, days, s=100, alpha=0.7, c=colors[0])
            axes[1, 0].set_title(f'æœ€é«˜æ°”æ¸©å‡ºç°æ—¥æœŸé¢„æµ‹ ({best_model})', fontweight='bold')
            axes[1, 0].set_xlabel('æœˆä»½')
            axes[1, 0].set_ylabel('æ—¥æœŸ')
            axes[1, 0].grid(True, alpha=0.3)
            
            # æ¸©åº¦è¶‹åŠ¿å¯¹æ¯”
            historical_yearly_max = self.processed_data.groupby('year')['temperature'].max()
            future_max_temps = [p['max_temperature'] for p in best_predictions]
            future_years = [p['year'] for p in best_predictions]
            
            axes[1, 1].plot(historical_yearly_max.index, historical_yearly_max.values, 
                          'b-', linewidth=2, alpha=0.7, label='å†å²æ•°æ®')
            axes[1, 1].plot(future_years, future_max_temps, 
                          'r-', linewidth=3, marker='o', markersize=8, label='é¢„æµ‹æ•°æ®')
            axes[1, 1].set_title('å†å²ä¸é¢„æµ‹æ¸©åº¦è¶‹åŠ¿å¯¹æ¯”', fontweight='bold')
            axes[1, 1].set_xlabel('å¹´ä»½')
            axes[1, 1].set_ylabel('æœ€é«˜æ¸©åº¦ (Â°C)')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(f'{output_dir}/intelligent_temperature_predictions.png', dpi=300, bbox_inches='tight')
            plt.close()
        
        print("âœ… å¯è§†åŒ–å›¾è¡¨åˆ›å»ºå®Œæˆ!")
    
    def generate_report(self):
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š
        """
        print("ğŸ“ æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        import os
        output_dir = "outputs"
        os.makedirs(output_dir, exist_ok=True)
        
        report_path = f"{output_dir}/intelligent_temperature_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ä¸Šæµ·åœ°åŒºå¤å­£æœ€é«˜æ°”æ¸©æ™ºèƒ½é¢„æµ‹åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"åˆ†æåŒºåŸŸ: ä¸Šæµ·åœ°åŒº (ä¸œç»{self.lon_range[0]:.2f}Â°-{self.lon_range[1]:.2f}Â°, åŒ—çº¬{self.lat_range[0]:.2f}Â°-{self.lat_range[1]:.2f}Â°)\n\n")
            
            # æ•°æ®æ¦‚å†µ
            f.write("## æ•°æ®æ¦‚å†µ\n")
            f.write(f"- åˆ†æå¹´ä»½: {self.processed_data['year'].min()} - {self.processed_data['year'].max()}\n")
            f.write(f"- æ•°æ®ç‚¹æ•°: {len(self.processed_data)} ä¸ª\n")
            f.write(f"- å¹³å‡æ°”æ¸©: {self.processed_data['temperature'].mean():.1f}Â°C\n")
            f.write(f"- æœ€é«˜æ°”æ¸©: {self.processed_data['temperature'].max():.1f}Â°C\n")
            f.write(f"- æœ€ä½æ°”æ¸©: {self.processed_data['temperature'].min():.1f}Â°C\n")
            f.write(f"- é«˜æ¸©å¤©æ•°(>{self.shanghai_climate['heat_wave_threshold']}Â°C): {(self.processed_data['temperature'] > self.shanghai_climate['heat_wave_threshold']).sum()} å¤©\n\n")
            
            # æ·±åº¦å­¦ä¹ æ¨¡å‹æ€§èƒ½
            f.write("## æ·±åº¦å­¦ä¹ æ¨¡å‹æ€§èƒ½\n")
            for model_name, model_info in self.models.items():
                f.write(f"- {model_name}: MAE = {model_info['score']:.4f}\n")
            
            best_model = min(self.models.keys(), key=lambda x: self.models[x]['score'])
            f.write(f"\næœ€ä½³æ¨¡å‹: {best_model}\n\n")
            
            # æœªæ¥é¢„æµ‹
            if 'future_predictions' in self.results:
                f.write("## æœªæ¥é¢„æµ‹ç»“æœ\n")
                best_predictions = self.results['future_predictions'][best_model]
                
                for pred in best_predictions:
                    date_str = pred['max_temp_date'].strftime('%mæœˆ%dæ—¥')
                    f.write(f"- {pred['year']}å¹´: æœ€é«˜æ°”æ¸© {pred['max_temperature']:.1f}Â°C, å‡ºç°æ—¥æœŸ {date_str}\n")
                    f.write(f"  å¤å­£å¹³å‡æ°”æ¸©: {pred['avg_summer_temp']:.1f}Â°C\n")
                
                # è¶‹åŠ¿åˆ†æ
                temps = [p['max_temperature'] for p in best_predictions]
                if len(temps) > 1:
                    trend = (temps[-1] - temps[0]) / (len(temps) - 1)
                    f.write(f"\né¢„æµ‹è¶‹åŠ¿: æ¯å¹´å˜åŒ– {trend:+.2f}Â°C\n")
            
            # æ°”å€™é£é™©è¯„ä¼°
            f.write("\n## æ°”å€™é£é™©è¯„ä¼°\n")
            if 'future_predictions' in self.results:
                future_max_temps = [p['max_temperature'] for p in best_predictions]
                extreme_heat_years = [p['year'] for p in best_predictions 
                                    if p['max_temperature'] > 38.0]
                
                f.write(f"- é¢„æµ‹æœŸå†…æœ€é«˜æ¸©åº¦: {max(future_max_temps):.1f}Â°C\n")
                f.write(f"- æç«¯é«˜æ¸©å¹´ä»½(>38Â°C): {extreme_heat_years}\n")
                f.write(f"- é«˜æ¸©é£é™©ç­‰çº§: {'é«˜' if max(future_max_temps) > 39 else 'ä¸­' if max(future_max_temps) > 37 else 'ä½'}\n")
            
            f.write("\n## å»ºè®®æªæ–½\n")
            f.write("- åŠ å¼ºå¤å­£é«˜æ¸©é¢„è­¦ç³»ç»Ÿ\n")
            f.write("- å®Œå–„åŸå¸‚çƒ­å²›æ•ˆåº”ç¼“è§£æªæ–½\n")
            f.write("- æå‡å…¬å…±åœºæ‰€é™æ¸©è®¾æ–½\n")
            f.write("- åˆ¶å®šæç«¯é«˜æ¸©åº”æ€¥é¢„æ¡ˆ\n")
        
        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
    
    def run_analysis(self):
        """
        è¿è¡Œå®Œæ•´çš„æ™ºèƒ½åˆ†ææµç¨‹
        """
        print("ğŸš€ å¼€å§‹æ™ºèƒ½å¤å­£æœ€é«˜æ°”æ¸©é¢„æµ‹åˆ†æ...")
        print("=" * 60)
        
        try:
            # 1. åŠ è½½æ•°æ®
            if self.grib_file_path:
                self.load_grib_data()
            else:
                self.load_data_from_db()
            
            # 2. åˆ›å»ºç‰¹å¾
            self.create_features()
            
            # 3. è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹
            self.train_models()
            
            # 4. é¢„æµ‹æœªæ¥æ¸©åº¦
            self.predict_future_temperatures()
            
            # 5. åˆ›å»ºå¯è§†åŒ–
            self.create_visualizations()
            
            # 6. ç”ŸæˆæŠ¥å‘Š
            self.generate_report()
            
            print("\n" + "=" * 60)
            print("ğŸ‰ æ™ºèƒ½åˆ†æå®Œæˆ! æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³ outputs/ ç›®å½•")
            print("\nğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
            print("  - intelligent_temperature_analysis.png (å†å²æ•°æ®åˆ†æ)")
            print("  - intelligent_temperature_predictions.png (æœªæ¥é¢„æµ‹å›¾è¡¨)")
            print("  - intelligent_temperature_report.txt (è¯¦ç»†åˆ†ææŠ¥å‘Š)")
            
            # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹çš„é¢„æµ‹ç»“æœ
            if 'future_predictions' in self.results:
                best_model = min(self.models.keys(), key=lambda x: self.models[x]['score'])
                best_predictions = self.results['future_predictions'][best_model]
                
                print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model}")
                print("ğŸ”® æœªæ¥é¢„æµ‹æ‘˜è¦:")
                for pred in best_predictions:
                    date_str = pred['max_temp_date'].strftime('%mæœˆ%dæ—¥')
                    print(f"  {pred['year']}å¹´: æœ€é«˜æ°”æ¸© {pred['max_temperature']:.1f}Â°C, å‡ºç°æ—¥æœŸ {date_str}")
            
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

# ä¸»ç¨‹åº
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Intelligent Summer Temperature Prediction System')
    parser.add_argument('--grib_file', type=str, help='Path to the GRIB file for analysis.')
    args = parser.parse_args()

    # åˆ›å»ºé¢„æµ‹ç³»ç»Ÿå®ä¾‹
    predictor = IntelligentTemperaturePrediction(args.grib_file)
    
    # è¿è¡Œåˆ†æ
    predictor.run_analysis()